{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3bf4d32",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f2400",
   "metadata": {},
   "source": [
    "# 0. Project Roadmap – Expedia Hotel Recommendation\n",
    "\n",
    "---\n",
    "\n",
    "This roadmap outlines the steps of our workflow:  \n",
    "from loading and preparing the data, through feature engineering, to model building and evaluation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1f306",
   "metadata": {},
   "source": [
    "## Table of Content + Introduction\n",
    "1. Data Preparation\n",
    "- Load datasets:\n",
    "  - `onlybookings.csv` (main training data, only booking events)\n",
    "  - `destinations.csv` (150-dimensional destination embeddings)\n",
    "- Inspect data structure, missing values, distributions\n",
    "- Handle missing values (e.g., distance)\n",
    "\n",
    "---\n",
    "\n",
    "2. Feature Engineering\n",
    "- **Date & time features**\n",
    "  - `season` (Spring, Summer, Autumn, Winter from `srch_ci`)\n",
    "  - `search_month`, `search_weekday`, `search_hour`\n",
    "  - `length_of_stay` = `(srch_co - srch_ci).days`\n",
    "  - `advance_days` = `(srch_ci - date_time).days`\n",
    "- **Geographic features**\n",
    "  - `distance_log` (log-transformed, imputed)\n",
    "  - `distance_was_missing` (binary flag)\n",
    "  - `same_country`, `same_continent`\n",
    "- **User & session features**\n",
    "  - `cnt_log` (log of number of similar events)\n",
    "  - `cnt_bin` (binned categories: single / few / many)\n",
    "  - `is_mobile`, `is_package`, `channel`\n",
    "- **Destination features**\n",
    "  - Run PCA on `destinations.csv` (reduce from 150 → 3 components)\n",
    "  - Join to main dataset via `srch_destination_id`\n",
    "  - Add `dest_pca1`, `dest_pca2`, `dest_pca3` to feature set\n",
    "\n",
    "---\n",
    "\n",
    "3. Baseline Model\n",
    "- Goal: simple first benchmark\n",
    "- Train a basic **Multinomial Logistic Regression** or **Random Forest**\n",
    "- Evaluate with:\n",
    "  - Accuracy (quick sanity check)\n",
    "  - MAP@5 (Kaggle evaluation metric)\n",
    "\n",
    "---\n",
    "\n",
    "4. Intermediate Models\n",
    "- Improve preprocessing:\n",
    "  - Scale numeric features\n",
    "  - One-Hot Encode categorical features\n",
    "- Try tree-based models:\n",
    "  - Random Forest\n",
    "  - Gradient Boosting (e.g., HistGradientBoostingClassifier)\n",
    "- Feature importance analysis\n",
    "\n",
    "---\n",
    "\n",
    "5. Advanced Model\n",
    "- Use more powerful models:\n",
    "  - XGBoost, LightGBM, or CatBoost (if available)\n",
    "- Apply **Target Encoding** for high-cardinality features:\n",
    "  - `srch_destination_id`\n",
    "  - `hotel_market`, `hotel_country`\n",
    "- Hyperparameter Tuning:\n",
    "  - RandomizedSearchCV or GridSearchCV\n",
    "- Evaluate again with MAP@5\n",
    "\n",
    "---\n",
    "\n",
    "#6. Model Comparison & Results\n",
    "- Summarize baseline vs intermediate vs advanced models\n",
    "- Compare MAP@5 scores\n",
    "- Document most important features (interpretability)\n",
    "\n",
    "---\n",
    "\n",
    "7. Conclusion & Next Steps\n",
    "- Insights about which features matter most\n",
    "- Ideas for further improvement (e.g., embeddings, deep learning, session-level modeling)\n",
    "- Reflection on challenges and learnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb964ea",
   "metadata": {},
   "source": [
    "### Feature Derivation (at a glance)\n",
    "\n",
    "| Feature | Source column(s) | Type | Transformation / Derivation | Encoding recommendation | Notes |\n",
    "|---|---|---|---|---|---|\n",
    "| `season` | `srch_ci` | categorical (4) | Map month → {Spring, Summer, Autumn, Winter} | One-Hot | Robust, low cardinality |\n",
    "| `search_month` | `date_time` | cyclical | Extract month (1–12), optional sin/cos | One-Hot or sin/cos | Use sin/cos to keep periodicity |\n",
    "| `search_weekday` | `date_time` | categorical (7) | Extract weekday (0–6) | One-Hot | Useful for business vs leisure patterns |\n",
    "| `search_hour` | `date_time` | cyclical | Extract hour (0–23), optional sin/cos | One-Hot or sin/cos | Hourly patterns can matter |\n",
    "| `length_of_stay` | `srch_ci`, `srch_co` | numeric | `(srch_co - srch_ci).days`, clip to [0, 30] | Scale (StandardScaler) or raw for trees | Outlier clipping stabilizes training |\n",
    "| `advance_days` | `srch_ci`, `date_time` | numeric | `(srch_ci - date_time).days`, clip to [0, 365] | Scale (StandardScaler) or raw for trees | Captures early vs last-minute booking |\n",
    "| `orig_destination_distance` | `orig_destination_distance` | numeric | Coerce to numeric; impute (group median by `season`,`hotel_market` → fallback global); optional log | Use `distance_log = log1p(imputed)` and scale | Add `distance_was_missing` flag |\n",
    "| `distance_was_missing` | `orig_destination_distance` | binary | `1` if original value missing | As is | Helps model “missingness” signal |\n",
    "| `distance_log` | `orig_destination_distance` | numeric | `log1p(imputed distance)` | Scale | Reduces skew / outliers |\n",
    "| `same_country` | `user_location_country`, `hotel_country` | binary | 1 if equal, else 0 | As is | Cheap but often predictive |\n",
    "| `same_continent` | `posa_continent`, `hotel_continent` | binary | 1 if equal, else 0 | As is | Adds geographic proximity signal |\n",
    "| `cnt_log` | `cnt` | numeric | `log1p(cnt)` | Scale | Smoother than raw `cnt` |\n",
    "| `cnt_bin` | `cnt` | categorical (3–4) | Bin: 1=single, 2–3=few, ≥4=many | One-Hot | Optional, complements `cnt_log` |\n",
    "| `is_mobile` | `is_mobile` | binary | — | As is / One-Hot | Device signal |\n",
    "| `is_package` | `is_package` | binary | — | As is / One-Hot | Package vs stand-alone |\n",
    "| `channel` | `channel` | categorical (low/med) | — | One-Hot | Marketing/acquisition signal |\n",
    "| `posa_continent` | `posa_continent` | categorical (low) | — | One-Hot | Origin continent |\n",
    "| `hotel_continent` | `hotel_continent` | categorical (low) | — | One-Hot | Destination continent |\n",
    "| `hotel_country` | `hotel_country` | categorical (med/high) | — | Target Encoding or OHE (if feasible) | Higher cardinality |\n",
    "| `hotel_market` | `hotel_market` | categorical (high) | — | Target Encoding / CatBoost / LightGBM | High cardinality; powerful |\n",
    "| `srch_destination_id` | `srch_destination_id` | categorical (very high) | — | Target Encoding / Embeddings | Very predictive of `hotel_cluster` but risky for overfitting; never One-Hot |\n",
    "\n",
    "---\n",
    "\n",
    "### Excluded / Handle-with-care (to avoid leakage or overfitting)\n",
    "\n",
    "| Column | Why exclude or transform |\n",
    "|---|---|\n",
    "| `hotel_cluster` | **Target label** — never use as feature |\n",
    "| `user_id` | High cardinality, user-specific leakage; don’t use for generalizable models |\n",
    "| Raw timestamps: `date_time`, `srch_ci`, `srch_co` | Use only via derived features (season, month, weekday, hour, length_of_stay, advance_days) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "669a3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0633b6f",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2de4bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape onlybookings: (1000001, 24)\n",
      "Shape destinations: (62106, 150)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Data\n",
    "# ================================\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load main training data (only bookings)\n",
    "df = pd.read_csv(\"data/onlybookings.csv\", low_memory=False)\n",
    "\n",
    "# Load destination embeddings (150 latent features)\n",
    "dest = pd.read_csv(\"data/destinations.csv\", low_memory=False)\n",
    "\n",
    "print(\"Shape onlybookings:\", df.shape)\n",
    "print(\"Shape destinations:\", dest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e950e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by 3 components: 0.5986751942782461\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dest_pca1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dest_pca2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dest_pca3",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "srch_destination_id",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "de25c083-5b63-4e81-843d-851e0544e27c",
       "rows": [
        [
         "0",
         "1.1795544922283774",
         "-1.4187098079384481",
         "-0.7346994850689579",
         "0"
        ],
        [
         "1",
         "6.60542543316478",
         "0.2495407284009061",
         "0.5998167660218798",
         "1"
        ],
        [
         "2",
         "-1.1538778169970476",
         "-0.3030589843132366",
         "0.9273103508570872",
         "2"
        ],
        [
         "3",
         "7.358539372285063",
         "0.3941874691097932",
         "-0.05671314531436729",
         "3"
        ],
        [
         "4",
         "3.7279677757243475",
         "0.5848713354386763",
         "0.4033747903577012",
         "4"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dest_pca1</th>\n",
       "      <th>dest_pca2</th>\n",
       "      <th>dest_pca3</th>\n",
       "      <th>srch_destination_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.179554</td>\n",
       "      <td>-1.418710</td>\n",
       "      <td>-0.734699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.605425</td>\n",
       "      <td>0.249541</td>\n",
       "      <td>0.599817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.153878</td>\n",
       "      <td>-0.303059</td>\n",
       "      <td>0.927310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.358539</td>\n",
       "      <td>0.394187</td>\n",
       "      <td>-0.056713</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.727968</td>\n",
       "      <td>0.584871</td>\n",
       "      <td>0.403375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dest_pca1  dest_pca2  dest_pca3  srch_destination_id\n",
       "0   1.179554  -1.418710  -0.734699                    0\n",
       "1   6.605425   0.249541   0.599817                    1\n",
       "2  -1.153878  -0.303059   0.927310                    2\n",
       "3   7.358539   0.394187  -0.056713                    3\n",
       "4   3.727968   0.584871   0.403375                    4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: PCA on destinations.csv\n",
    "# ================================\n",
    "\n",
    "# Remove id column (srch_destination_id) from PCA input\n",
    "dest_id = dest[\"srch_destination_id\"]\n",
    "dest_features = dest.drop(\"srch_destination_id\", axis=1)\n",
    "\n",
    "# Standardize features before PCA\n",
    "scaler = StandardScaler()\n",
    "dest_scaled = scaler.fit_transform(dest_features)\n",
    "\n",
    "# Run PCA (reduce 150 → 3 components)\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "dest_pca = pca.fit_transform(dest_scaled)\n",
    "\n",
    "# Put into DataFrame with srch_destination_id\n",
    "dest_pca_df = pd.DataFrame(dest_pca, columns=[\"dest_pca1\",\"dest_pca2\",\"dest_pca3\"])\n",
    "dest_pca_df[\"srch_destination_id\"] = dest_id.values\n",
    "\n",
    "print(\"Explained variance by 3 components:\", pca.explained_variance_ratio_.sum())\n",
    "dest_pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff5138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after join: (1000001, 27)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "srch_destination_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dest_pca1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dest_pca2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dest_pca3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0156fb04-d26f-4878-bd96-163760d1b413",
       "rows": [
        [
         "0",
         "8250",
         "-45.864356505796195",
         "-4.722330018510887",
         "-10.897557854908323"
        ],
        [
         "1",
         "8250",
         "-45.864356505796195",
         "-4.722330018510887",
         "-10.897557854908323"
        ],
        [
         "2",
         "8291",
         "-19.182445195742666",
         "7.503545539226985",
         "4.1904291336781965"
        ],
        [
         "3",
         "1385",
         "-9.925174887770474",
         "-7.212029044898108",
         "9.635184198673832"
        ],
        [
         "4",
         "8803",
         "-11.895227902505885",
         "3.6326208993822817",
         "2.2069500034973997"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>dest_pca1</th>\n",
       "      <th>dest_pca2</th>\n",
       "      <th>dest_pca3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8250</td>\n",
       "      <td>-45.864357</td>\n",
       "      <td>-4.722330</td>\n",
       "      <td>-10.897558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8250</td>\n",
       "      <td>-45.864357</td>\n",
       "      <td>-4.722330</td>\n",
       "      <td>-10.897558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8291</td>\n",
       "      <td>-19.182445</td>\n",
       "      <td>7.503546</td>\n",
       "      <td>4.190429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1385</td>\n",
       "      <td>-9.925175</td>\n",
       "      <td>-7.212029</td>\n",
       "      <td>9.635184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8803</td>\n",
       "      <td>-11.895228</td>\n",
       "      <td>3.632621</td>\n",
       "      <td>2.206950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_destination_id  dest_pca1  dest_pca2  dest_pca3\n",
       "0                 8250 -45.864357  -4.722330 -10.897558\n",
       "1                 8250 -45.864357  -4.722330 -10.897558\n",
       "2                 8291 -19.182445   7.503546   4.190429\n",
       "3                 1385  -9.925175  -7.212029   9.635184\n",
       "4                 8803 -11.895228   3.632621   2.206950"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Left Join\n",
    "# ================================\n",
    "# Merge PCA features into main bookings dataset\n",
    "df = df.merge(dest_pca_df, on=\"srch_destination_id\", how=\"left\")\n",
    "\n",
    "print(\"Shape after join:\", df.shape)\n",
    "df[[\"srch_destination_id\",\"dest_pca1\",\"dest_pca2\",\"dest_pca3\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aa7984",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9aead8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features prepared: 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "season",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "search_month",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "search_weekday",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "search_hour",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "length_of_stay",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "advance_days",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "distance_log",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "distance_was_missing",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cnt_log",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "cnt_bin",
         "rawType": "category",
         "type": "unknown"
        },
        {
         "name": "is_mobile",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_package",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "channel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "posa_continent",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hotel_continent",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hotel_country",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hotel_market",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "same_country",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "same_continent",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "dest_pca1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dest_pca2",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dest_pca3",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3582578f-c6d0-4daa-bc2f-921dfad7e306",
       "rows": [
        [
         "0",
         "Summer",
         "8",
         "0",
         "7",
         "4",
         "15",
         "7.712114665614769",
         "0",
         "1.3862943611198906",
         "few",
         "0",
         "1",
         "9",
         "3",
         "2",
         "50",
         "628",
         "0",
         "0",
         "-45.864356505796195",
         "-4.722330018510887",
         "-10.897557854908323"
        ],
        [
         "1",
         "Summer",
         "8",
         "0",
         "8",
         "4",
         "17",
         "7.712114665614769",
         "0",
         "0.6931471805599453",
         "single",
         "0",
         "1",
         "9",
         "3",
         "2",
         "50",
         "628",
         "0",
         "0",
         "-45.864356505796195",
         "-4.722330018510887",
         "-10.897557854908323"
        ],
        [
         "2",
         "Spring",
         "2",
         "3",
         "18",
         "2",
         "49",
         "6.689967733625912",
         "1",
         "0.6931471805599453",
         "single",
         "0",
         "1",
         "4",
         "3",
         "2",
         "50",
         "191",
         "0",
         "0",
         "-19.182445195742666",
         "7.503545539226985",
         "4.1904291336781965"
        ],
        [
         "3",
         "Autumn",
         "6",
         "5",
         "15",
         "8",
         "82",
         "6.689967733625912",
         "1",
         "0.6931471805599453",
         "single",
         "0",
         "1",
         "9",
         "4",
         "0",
         "185",
         "185",
         "0",
         "0",
         "-9.925174887770474",
         "-7.212029044898108",
         "9.635184198673832"
        ],
        [
         "4",
         "Summer",
         "11",
         "6",
         "18",
         "2",
         "214",
         "6.689967733625912",
         "1",
         "0.6931471805599453",
         "single",
         "0",
         "0",
         "9",
         "4",
         "3",
         "151",
         "69",
         "0",
         "0",
         "-11.895227902505885",
         "3.6326208993822817",
         "2.2069500034973997"
        ]
       ],
       "shape": {
        "columns": 22,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>search_month</th>\n",
       "      <th>search_weekday</th>\n",
       "      <th>search_hour</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>advance_days</th>\n",
       "      <th>distance_log</th>\n",
       "      <th>distance_was_missing</th>\n",
       "      <th>cnt_log</th>\n",
       "      <th>cnt_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>channel</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>same_country</th>\n",
       "      <th>same_continent</th>\n",
       "      <th>dest_pca1</th>\n",
       "      <th>dest_pca2</th>\n",
       "      <th>dest_pca3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summer</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>7.712115</td>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>few</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-45.864357</td>\n",
       "      <td>-4.722330</td>\n",
       "      <td>-10.897558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summer</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>7.712115</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>single</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-45.864357</td>\n",
       "      <td>-4.722330</td>\n",
       "      <td>-10.897558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spring</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>6.689968</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>single</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.182445</td>\n",
       "      <td>7.503546</td>\n",
       "      <td>4.190429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Autumn</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>6.689968</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>single</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.925175</td>\n",
       "      <td>-7.212029</td>\n",
       "      <td>9.635184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summer</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>214</td>\n",
       "      <td>6.689968</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>single</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-11.895228</td>\n",
       "      <td>3.632621</td>\n",
       "      <td>2.206950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  search_month  search_weekday  search_hour  length_of_stay  \\\n",
       "0  Summer             8               0            7               4   \n",
       "1  Summer             8               0            8               4   \n",
       "2  Spring             2               3           18               2   \n",
       "3  Autumn             6               5           15               8   \n",
       "4  Summer            11               6           18               2   \n",
       "\n",
       "   advance_days  distance_log  distance_was_missing   cnt_log cnt_bin  ...  \\\n",
       "0            15      7.712115                     0  1.386294     few  ...   \n",
       "1            17      7.712115                     0  0.693147  single  ...   \n",
       "2            49      6.689968                     1  0.693147  single  ...   \n",
       "3            82      6.689968                     1  0.693147  single  ...   \n",
       "4           214      6.689968                     1  0.693147  single  ...   \n",
       "\n",
       "   channel  posa_continent  hotel_continent  hotel_country  hotel_market  \\\n",
       "0        9               3                2             50           628   \n",
       "1        9               3                2             50           628   \n",
       "2        4               3                2             50           191   \n",
       "3        9               4                0            185           185   \n",
       "4        9               4                3            151            69   \n",
       "\n",
       "   same_country  same_continent  dest_pca1  dest_pca2  dest_pca3  \n",
       "0             0               0 -45.864357  -4.722330 -10.897558  \n",
       "1             0               0 -45.864357  -4.722330 -10.897558  \n",
       "2             0               0 -19.182445   7.503546   4.190429  \n",
       "3             0               0  -9.925175  -7.212029   9.635184  \n",
       "4             0               0 -11.895228   3.632621   2.206950  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================\n",
    "# Step 2: Feature Engineering\n",
    "# ================================\n",
    "\n",
    "# --- Date & Time Features ---\n",
    "df[\"date_time\"] = pd.to_datetime(df[\"date_time\"], errors=\"coerce\")\n",
    "df[\"srch_ci\"]   = pd.to_datetime(df[\"srch_ci\"], errors=\"coerce\")\n",
    "df[\"srch_co\"]   = pd.to_datetime(df[\"srch_co\"], errors=\"coerce\")\n",
    "\n",
    "# Season feature\n",
    "def month_to_season(m):\n",
    "    if pd.isna(m): return np.nan\n",
    "    if m in (12, 1, 2):  return \"Winter\"\n",
    "    if m in (3, 4, 5):   return \"Spring\"\n",
    "    if m in (6, 7, 8):   return \"Summer\"\n",
    "    return \"Autumn\"\n",
    "\n",
    "df[\"season\"] = df[\"srch_ci\"].dt.month.map(month_to_season)\n",
    "\n",
    "# Month, weekday, hour\n",
    "df[\"search_month\"]   = df[\"date_time\"].dt.month\n",
    "df[\"search_weekday\"] = df[\"date_time\"].dt.weekday\n",
    "df[\"search_hour\"]    = df[\"date_time\"].dt.hour\n",
    "\n",
    "# Length of stay (clip to avoid extreme outliers)\n",
    "df[\"length_of_stay\"] = (df[\"srch_co\"] - df[\"srch_ci\"]).dt.days\n",
    "df[\"length_of_stay\"] = df[\"length_of_stay\"].clip(lower=0, upper=30)\n",
    "\n",
    "# Advance booking days (clip as well)\n",
    "df[\"advance_days\"] = (df[\"srch_ci\"] - df[\"date_time\"]).dt.days\n",
    "df[\"advance_days\"] = df[\"advance_days\"].clip(lower=0, upper=365)\n",
    "\n",
    "# --- Distance Features ---\n",
    "df[\"orig_destination_distance\"] = pd.to_numeric(df[\"orig_destination_distance\"], errors=\"coerce\")\n",
    "\n",
    "# Median imputation (global fallback)\n",
    "global_med = df[\"orig_destination_distance\"].median()\n",
    "df[\"distance_imputed\"] = df[\"orig_destination_distance\"].fillna(global_med)\n",
    "\n",
    "# Log transform\n",
    "df[\"distance_log\"] = np.log1p(df[\"distance_imputed\"])\n",
    "\n",
    "# Missingness flag\n",
    "df[\"distance_was_missing\"] = df[\"orig_destination_distance\"].isna().astype(int)\n",
    "\n",
    "# --- User & Session Features ---\n",
    "df[\"cnt\"] = pd.to_numeric(df[\"cnt\"], errors=\"coerce\")\n",
    "df[\"cnt_log\"] = np.log1p(df[\"cnt\"])\n",
    "\n",
    "# Bin categories for cnt\n",
    "df[\"cnt_bin\"] = pd.cut(\n",
    "    df[\"cnt\"],\n",
    "    bins=[0,1,3,1000],  # adapt bins if needed\n",
    "    labels=[\"single\",\"few\",\"many\"],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# --- Geographic Flags ---\n",
    "df[\"same_country\"] = (df[\"user_location_country\"] == df[\"hotel_country\"]).astype(int)\n",
    "df[\"same_continent\"] = (df[\"posa_continent\"] == df[\"hotel_continent\"]).astype(int)\n",
    "\n",
    "# --- Keep PCA features ---\n",
    "# Already joined: dest_pca1, dest_pca2, dest_pca3\n",
    "\n",
    "# --- Final check ---\n",
    "feature_cols = [\n",
    "    \"season\",\"search_month\",\"search_weekday\",\"search_hour\",\n",
    "    \"length_of_stay\",\"advance_days\",\n",
    "    \"distance_log\",\"distance_was_missing\",\n",
    "    \"cnt_log\",\"cnt_bin\",\n",
    "    \"is_mobile\",\"is_package\",\"channel\",\n",
    "    \"posa_continent\",\"hotel_continent\",\"hotel_country\",\"hotel_market\",\n",
    "    \"same_country\",\"same_continent\",\n",
    "    \"dest_pca1\",\"dest_pca2\",\"dest_pca3\"\n",
    "]\n",
    "\n",
    "print(\"Number of features prepared:\", len(feature_cols))\n",
    "df[feature_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315c61d",
   "metadata": {},
   "source": [
    "# 3. Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c190296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.1640\n",
      "Validation MAP@5:   0.2761\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Baseline Model\n",
    "# ================================\n",
    "\n",
    "target = \"hotel_cluster\"\n",
    "\n",
    "numeric_features = [\n",
    "    \"length_of_stay\",\"advance_days\",\"distance_log\",\"cnt_log\",\n",
    "    \"distance_was_missing\",\"same_country\",\"same_continent\",\n",
    "    \"dest_pca1\",\"dest_pca2\",\"dest_pca3\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"season\",\"search_month\",\"search_weekday\",\"search_hour\",\n",
    "    \"cnt_bin\",\"is_mobile\",\"is_package\",\"channel\",\n",
    "    \"posa_continent\",\"hotel_continent\",\"hotel_country\",\"hotel_market\"\n",
    "]\n",
    "\n",
    "# Drop rows with missing target just in case\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[target].astype(int)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---- Preprocessing with Imputers (CRITICAL FIX) ----\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),   # NEW\n",
    "    (\"scaler\",  StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # NEW\n",
    "    (\"ohe\",     OneHotEncoder(handle_unknown=\"ignore\", sparse=True))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"saga\",\n",
    "    max_iter=200,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluation ---\n",
    "y_pred = pipe.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "def map_at_k(y_true, proba, classes, k=5):\n",
    "    topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
    "    topk_labels = classes[topk_idx]\n",
    "    rr = []\n",
    "    for t, row in zip(y_true, topk_labels):\n",
    "        if t in row:\n",
    "            rank = np.where(row == t)[0][0] + 1\n",
    "            rr.append(1.0 / rank)\n",
    "        else:\n",
    "            rr.append(0.0)\n",
    "    return float(np.mean(rr))\n",
    "\n",
    "proba_val = pipe.predict_proba(X_val)\n",
    "classes_  = pipe.named_steps[\"clf\"].classes_\n",
    "map5 = map_at_k(y_val.values, proba_val, classes_, k=5)\n",
    "\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "print(f\"Validation MAP@5:   {map5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf00f5d",
   "metadata": {},
   "source": [
    "# 4. Intermediate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b8a0be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (HGBT): 0.1578\n",
      "Validation MAP@5 (HGBT):   0.2619\n"
     ]
    }
   ],
   "source": [
    "# --- Features ---\n",
    "numeric_features = [\n",
    "    \"length_of_stay\",\"advance_days\",\"distance_log\",\"cnt_log\",\n",
    "    \"distance_was_missing\",\"same_country\",\"same_continent\",\n",
    "    \"dest_pca1\",\"dest_pca2\",\"dest_pca3\"\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"season\",\"search_month\",\"search_weekday\",\"search_hour\",\n",
    "    \"cnt_bin\",\"is_mobile\",\"is_package\",\"channel\",\n",
    "    \"posa_continent\",\"hotel_continent\",\"hotel_country\",\"hotel_market\"\n",
    "]\n",
    "\n",
    "target = \"hotel_cluster\"\n",
    "\n",
    "# --- Split ---\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[target].astype(int)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Preprocessing ---\n",
    "# Numerics: impute missing with median\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "# Categoricals: impute missing + encode as integers\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, numeric_features),\n",
    "        (\"cat\", cat_pipe, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Model ---\n",
    "clf = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=10,\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "# --- Train ---\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = pipe.predict(X_val)\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Probabilities for MAP@5\n",
    "proba_val = pipe.predict_proba(X_val)\n",
    "classes_  = pipe.named_steps[\"clf\"].classes_\n",
    "\n",
    "def map_at_k(y_true, proba, classes, k=5):\n",
    "    topk_idx = np.argsort(-proba, axis=1)[:, :k]\n",
    "    topk_labels = classes[topk_idx]\n",
    "    rr = []\n",
    "    for t, row in zip(y_true, topk_labels):\n",
    "        if t in row:\n",
    "            rank = np.where(row == t)[0][0] + 1\n",
    "            rr.append(1.0 / rank)\n",
    "        else:\n",
    "            rr.append(0.0)\n",
    "    return float(np.mean(rr))\n",
    "\n",
    "map5 = map_at_k(y_val.values, proba_val, classes_, k=5)\n",
    "\n",
    "print(f\"Validation Accuracy (HGBT): {acc:.4f}\")\n",
    "print(f\"Validation MAP@5 (HGBT):   {map5:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import parallel_backend\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Top-5 MAP/Recall@5 as Scorer – top-level defined (picklable)\n",
    "def map5_scorer(estimator, X, y):\n",
    "    proba = estimator.predict_proba(X)\n",
    "    top5_idx = np.argsort(proba, axis=1)[:, -5:][:, ::-1]\n",
    "    preds = estimator.classes_[top5_idx]\n",
    "    y = np.asarray(y)\n",
    "    hits = (preds == y.reshape(-1,1)).any(axis=1)\n",
    "    return hits.mean()\n",
    "\n",
    "with parallel_backend('threading'):  # threads instead of processes\n",
    "    result = permutation_importance(\n",
    "        pipe, X_val, y_val,\n",
    "        n_repeats=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        scoring=map5_scorer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d607fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importance_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "importance_std",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "59c3b0e3-d2a3-496a-bfab-602a1c788e79",
       "rows": [
        [
         "0",
         "dest_pca1",
         "0.18018109909450447",
         "0.0006642902883326628"
        ],
        [
         "1",
         "hotel_continent",
         "0.14216728916355417",
         "0.0007747580251181755"
        ],
        [
         "2",
         "hotel_market",
         "0.11678641606791965",
         "0.0003813063677030545"
        ],
        [
         "3",
         "dest_pca2",
         "0.11001744991275042",
         "0.0005458415709364207"
        ],
        [
         "4",
         "dest_pca3",
         "0.10616046919765398",
         "0.0006264663401887012"
        ],
        [
         "5",
         "hotel_country",
         "0.06791366043169782",
         "0.000387262830996284"
        ],
        [
         "6",
         "length_of_stay",
         "0.005073974630126843",
         "0.00014619776421546815"
        ],
        [
         "7",
         "advance_days",
         "0.0039719801400992846",
         "0.0002267498309676459"
        ],
        [
         "8",
         "distance_log",
         "0.002439987800060983",
         "9.148724665562144e-05"
        ],
        [
         "9",
         "is_package",
         "0.0017599912000439866",
         "9.386113093640881e-05"
        ],
        [
         "10",
         "search_month",
         "0.0016869915650421618",
         "0.00016794558029942873"
        ],
        [
         "11",
         "posa_continent",
         "0.0010809945950270073",
         "0.00011791463421068539"
        ],
        [
         "12",
         "same_continent",
         "0.0005889970550147061",
         "3.786800311750084e-05"
        ],
        [
         "13",
         "season",
         "0.0004459977700111306",
         "4.386320508288965e-05"
        ],
        [
         "14",
         "search_hour",
         "0.00020699896500515625",
         "6.071213338597845e-05"
        ],
        [
         "15",
         "distance_was_missing",
         "0.00016199919000403629",
         "5.11465916772079e-05"
        ],
        [
         "16",
         "channel",
         "0.00014899925500370115",
         "2.7092298906795217e-05"
        ],
        [
         "17",
         "is_mobile",
         "4.099979500099549e-05",
         "1.714634246777865e-05"
        ],
        [
         "18",
         "same_country",
         "3.299983500081316e-05",
         "5.098994018624492e-06"
        ],
        [
         "19",
         "search_weekday",
         "7.999960000182327e-06",
         "6.592386927604919e-05"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance_mean</th>\n",
       "      <th>importance_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dest_pca1</td>\n",
       "      <td>0.180181</td>\n",
       "      <td>0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hotel_continent</td>\n",
       "      <td>0.142167</td>\n",
       "      <td>0.000775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hotel_market</td>\n",
       "      <td>0.116786</td>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dest_pca2</td>\n",
       "      <td>0.110017</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dest_pca3</td>\n",
       "      <td>0.106160</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hotel_country</td>\n",
       "      <td>0.067914</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>length_of_stay</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>advance_days</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>distance_log</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is_package</td>\n",
       "      <td>0.001760</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>search_month</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>posa_continent</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>same_continent</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>season</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>search_hour</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>distance_was_missing</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>channel</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>is_mobile</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>same_country</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>search_weekday</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature  importance_mean  importance_std\n",
       "0              dest_pca1         0.180181        0.000664\n",
       "1        hotel_continent         0.142167        0.000775\n",
       "2           hotel_market         0.116786        0.000381\n",
       "3              dest_pca2         0.110017        0.000546\n",
       "4              dest_pca3         0.106160        0.000626\n",
       "5          hotel_country         0.067914        0.000387\n",
       "6         length_of_stay         0.005074        0.000146\n",
       "7           advance_days         0.003972        0.000227\n",
       "8           distance_log         0.002440        0.000091\n",
       "9             is_package         0.001760        0.000094\n",
       "10          search_month         0.001687        0.000168\n",
       "11        posa_continent         0.001081        0.000118\n",
       "12        same_continent         0.000589        0.000038\n",
       "13                season         0.000446        0.000044\n",
       "14           search_hour         0.000207        0.000061\n",
       "15  distance_was_missing         0.000162        0.000051\n",
       "16               channel         0.000149        0.000027\n",
       "17             is_mobile         0.000041        0.000017\n",
       "18          same_country         0.000033        0.000005\n",
       "19        search_weekday         0.000008        0.000066"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Features: 22\n"
     ]
    }
   ],
   "source": [
    "# 1) Feature-names robust\n",
    "try:\n",
    "    # frequent: pipe = Pipeline([(\"preproc\", coltx), (\"model\", clf)])\n",
    "    feature_names = pipe.named_steps[\"preproc\"].get_feature_names_out()\n",
    "except Exception:\n",
    "    # Fallback:\n",
    "    feature_names = numeric_features + categorical_features\n",
    "\n",
    "# 2) target object in df\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance_mean\": result.importances_mean,\n",
    "    \"importance_std\": result.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 3) overview\n",
    "display(imp_df.head(20))\n",
    "print(f\"Anzahl Features: {len(imp_df)}\")\n",
    "\n",
    "# 4) Optional: save\n",
    "# # imp_df.to_csv(\"permutation_importance_map5.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153208f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['channel', 'cnt_bin', 'distance_was_missing', 'hotel_continent', 'hotel_country', 'hotel_market', 'is_mobile', 'is_package', 'posa_continent', 'same_continent', 'same_country', 'search_hour', 'search_month', 'search_weekday', 'season', 'srch_destination_id']\n",
      "Numeric features: ['date_time', 'site_name', 'user_location_country', 'user_location_region', 'user_location_city', 'orig_destination_distance', 'user_id', 'srch_ci', 'srch_co', 'srch_adults_cnt', 'srch_children_cnt', 'srch_rm_cnt', 'srch_destination_type_id', 'is_booking', 'cnt', 'dest_pca1', 'dest_pca2', 'dest_pca3', 'length_of_stay', 'advance_days', 'distance_imputed', 'distance_log', 'cnt_log']\n",
      "0:\tlearn: 4.3548180\ttest: 4.3555767\tbest: 4.3555767 (0)\ttotal: 2m 3s\tremaining: 13h 43m 25s\n"
     ]
    }
   ],
   "source": [
    "# CatBoost Safe-Mode Patch \n",
    "# =========================\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# --- 0) Target + Features ---\n",
    "target = \"hotel_cluster\"\n",
    "features = [c for c in df.columns if c != target]\n",
    "\n",
    "# --- 1) Downcast numerics to save RAM ---\n",
    "num_cols = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "if num_cols:\n",
    "    df[num_cols] = df[num_cols].apply(pd.to_numeric, downcast=\"integer\")\n",
    "    df[num_cols] = df[num_cols].apply(pd.to_numeric, downcast=\"float\")\n",
    "\n",
    "# --- 2) Cap high-cardinality categoricals (to avoid memory blow-up) ---\n",
    "def cap_top_k(series, k=200):\n",
    "    top = series.value_counts(dropna=False).nlargest(k).index\n",
    "    return series.where(series.isin(top), other=\"other\")\n",
    "\n",
    "high_card_cols = [c for c in [\"hotel_market\",\"srch_destination_id\",\"hotel_country\"] if c in df.columns]\n",
    "for c in high_card_cols:\n",
    "    df[c] = df[c].astype(\"object\").fillna(\"missing\")\n",
    "    df[c] = cap_top_k(df[c], k=200)\n",
    "\n",
    "# --- 3) Detect categorical features ---\n",
    "auto_cats = [c for c in features if str(df[c].dtype) in (\"object\",\"category\")]\n",
    "known_cats = {\n",
    "    \"hotel_continent\",\"hotel_market\",\"hotel_country\",\n",
    "    \"search_month\",\"search_weekday\",\"search_hour\",\"season\",\n",
    "    \"is_package\",\"is_mobile\",\"same_country\",\"same_continent\",\"distance_was_missing\",\n",
    "    \"srch_destination_id\",\"posa_continent\",\"channel\",\"cnt_bin\"\n",
    "}\n",
    "cat_features = sorted(set(auto_cats).union(known_cats.intersection(features)))\n",
    "num_features = [c for c in features if c not in cat_features]\n",
    "\n",
    "# Ensure categoricals are strings with explicit \"missing\"\n",
    "for c in cat_features:\n",
    "    df[c] = df[c].astype(\"object\").fillna(\"missing\")\n",
    "\n",
    "print(\"Categorical features:\", cat_features)\n",
    "print(\"Numeric features:\", num_features)\n",
    "\n",
    "# --- 4) Subsample for stability (scale up later) ---\n",
    "X_full = df[features]\n",
    "y_full = df[target].astype(int)\n",
    "\n",
    "sample_size = 250_000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if len(X_full) > sample_size:\n",
    "    X_sample, _, y_sample, _ = train_test_split(\n",
    "        X_full, y_full, train_size=sample_size, stratify=y_full, random_state=42\n",
    "    )\n",
    "else:\n",
    "    X_sample, y_sample = X_full, y_full\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_sample, y_sample, test_size=0.1, stratify=y_sample, random_state=42\n",
    ")\n",
    "\n",
    "# --- Make sure categorical columns are strings (no floats/NaNs) ---\n",
    "X_train = X_train.copy()\n",
    "X_val   = X_val.copy()\n",
    "\n",
    "def coerce_cats_to_str(df, cat_cols):\n",
    "    for c in cat_cols:\n",
    "        # If numeric-like, convert to pandas nullable int first to avoid float artifacts,\n",
    "        # then to string. Finally, ensure missing values become a clear token.\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            df[c] = df[c].astype('Int64').astype('string')\n",
    "        else:\n",
    "            df[c] = df[c].astype('string')\n",
    "        df[c] = df[c].fillna('missing')\n",
    "    return df\n",
    "\n",
    "X_train = coerce_cats_to_str(X_train, cat_features)\n",
    "X_val   = coerce_cats_to_str(X_val,   cat_features)\n",
    "\n",
    "# Rebuild cat_indices after any column changes (names unchanged, but safe to recompute)\n",
    "cat_indices = [X_train.columns.get_loc(c) for c in cat_features]\n",
    "\n",
    "# --- 5) Now build CatBoost Pools safely ---\n",
    "train_pool = Pool(X_train, label=y_train, cat_features=cat_indices)\n",
    "val_pool   = Pool(X_val,   label=y_val,   cat_features=cat_indices)\n",
    "\n",
    "\n",
    "# --- 6) Train CatBoost (safe params) ---\n",
    "params = dict(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"MultiClass\",\n",
    "    learning_rate=0.1,\n",
    "    iterations=400,          # increase stepwise when stable\n",
    "    depth=6,\n",
    "    max_bin=128,\n",
    "    l2_leaf_reg=3.0,\n",
    "    random_seed=42,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=40,\n",
    "    subsample=0.8,\n",
    "    rsm=0.8,\n",
    "    one_hot_max_size=16,\n",
    "    max_ctr_complexity=1,\n",
    "    bootstrap_type=\"Bernoulli\",\n",
    "    task_type=\"CPU\",\n",
    "    thread_count=2,\n",
    "    allow_writing_files=False,\n",
    ")\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(train_pool, eval_set=val_pool, verbose=100, use_best_model=True)\n",
    "\n",
    "# --- 7) Evaluate Accuracy + MAP@5 ---\n",
    "val_proba = model.predict_proba(X_val)\n",
    "val_pred  = np.argmax(val_proba, axis=1)\n",
    "acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "def mapk(y_true, y_proba, k=5):\n",
    "    y_true = np.asarray(y_true)\n",
    "    topk = np.argsort(-y_proba, axis=1)[:, :k]\n",
    "    hits = (topk == y_true[:, None])\n",
    "    first_hit_rank = (hits * (np.arange(1, k+1)[None, :])).max(axis=1)\n",
    "    scores = np.where(first_hit_rank > 0, 1.0 / first_hit_rank, 0.0)\n",
    "    return scores.mean()\n",
    "\n",
    "map5 = mapk(y_val.values, val_proba, k=5)\n",
    "\n",
    "print(f\"\\nValidation Accuracy (CatBoost, sample={len(X_train)+len(X_val):,}): {acc:.4f}\")\n",
    "print(f\"Validation MAP@5   (CatBoost, sample={len(X_train)+len(X_val):,}): {map5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "228b99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 24 features: ['dest_pca1', 'dest_pca2', 'dest_pca3', 'hotel_continent', 'hotel_market', 'hotel_country', 'length_of_stay', 'advance_days', 'distance_log', 'orig_destination_distance', 'cnt', 'cnt_bin', 'search_month', 'search_weekday', 'search_hour', 'season', 'is_package', 'is_mobile', 'same_country', 'same_continent', 'distance_was_missing', 'srch_destination_id', 'posa_continent', 'channel']\n",
      "Categorical features: ['channel', 'cnt_bin', 'distance_was_missing', 'hotel_continent', 'hotel_country', 'hotel_market', 'is_mobile', 'is_package', 'posa_continent', 'same_continent', 'same_country', 'search_hour', 'search_month', 'search_weekday', 'season', 'srch_destination_id']\n",
      "Numeric features: ['dest_pca1', 'dest_pca2', 'dest_pca3', 'length_of_stay', 'advance_days', 'distance_log', 'orig_destination_distance', 'cnt']\n",
      "Categorical features: ['hotel_continent', 'hotel_market', 'hotel_country', 'search_month', 'search_weekday', 'search_hour', 'season', 'is_package', 'is_mobile', 'same_country', 'same_continent', 'distance_was_missing', 'srch_destination_id', 'posa_continent', 'channel', 'cnt_bin']\n",
      "Numeric features: ['dest_pca1', 'dest_pca2', 'dest_pca3', 'length_of_stay', 'advance_days', 'distance_log', 'orig_destination_distance', 'cnt']\n",
      "Downsampled from 1,000,001 to 649,502 rows (100 classes).\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Fast CatBoost (Multiclass) on `df` with class-capped downsampling\n",
    "# =========================\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# ---------- 0) Columns ----------\n",
    "target_col = \"hotel_cluster\"\n",
    "\n",
    "# Candidate features (will filter to those that actually exist in df)\n",
    "candidate_features = [\n",
    "    # Top signal features (from your permutation importance)\n",
    "    \"dest_pca1\",\"dest_pca2\",\"dest_pca3\",\n",
    "    \"hotel_continent\",\"hotel_market\",\"hotel_country\",\n",
    "\n",
    "    # Useful numerics\n",
    "    \"length_of_stay\",\"advance_days\",\"distance_log\",\"orig_destination_distance\",\n",
    "    \"cnt\",\"cnt_bin\",\n",
    "\n",
    "    # Time & context\n",
    "    \"search_month\",\"search_weekday\",\"search_hour\",\"season\",\n",
    "\n",
    "    # Binary / flags\n",
    "    \"is_package\",\"is_mobile\",\"same_country\",\"same_continent\",\"distance_was_missing\",\n",
    "\n",
    "    # Other IDs that often help CatBoost\n",
    "    \"srch_destination_id\",\"posa_continent\",\"channel\"\n",
    "]\n",
    "\n",
    "features = [c for c in candidate_features if c in df.columns]\n",
    "print(f\"Using {len(features)} features:\", features)\n",
    "\n",
    "# --- replace the manual cat/num split with auto-detection + whitelist merge ---\n",
    "\n",
    "# 1) start from your curated categorical candidates\n",
    "categorical_candidates = [\n",
    "    \"hotel_continent\",\"hotel_market\",\"hotel_country\",\n",
    "    \"search_month\",\"search_weekday\",\"search_hour\",\"season\",\n",
    "    \"is_package\",\"is_mobile\",\"same_country\",\"same_continent\",\"distance_was_missing\",\n",
    "    \"srch_destination_id\",\"posa_continent\",\"channel\",\n",
    "    \"cnt_bin\",  # <- add this explicitly since it's often categorical\n",
    "]\n",
    "\n",
    "# keep only those that are present\n",
    "cat_features = [c for c in categorical_candidates if c in features]\n",
    "\n",
    "# 2) auto-add any column that has pandas dtype 'category' or 'object'\n",
    "auto_cats = [c for c in features if str(df[c].dtype) in (\"category\", \"object\")]\n",
    "cat_features = sorted(set(cat_features).union(auto_cats))\n",
    "\n",
    "# 3) define numeric features as the rest\n",
    "num_features = [c for c in features if c not in cat_features]\n",
    "\n",
    "print(\"Categorical features:\", cat_features)\n",
    "print(\"Numeric features:\", num_features)\n",
    "\n",
    "cat_features = [c for c in categorical_candidates if c in features]\n",
    "num_features = [c for c in features if c not in cat_features]\n",
    "\n",
    "# Ensure categorical columns are strings with explicit \"missing\"\n",
    "for c in cat_features:\n",
    "    X[c] = df[c].astype(\"object\").fillna(\"missing\")\n",
    "\n",
    "\n",
    "print(\"Categorical features:\", cat_features)\n",
    "print(\"Numeric features:\", num_features)\n",
    "\n",
    "# ---------- 2) Basic cleaning / NA handling ----------\n",
    "# CatBoost can handle NaNs, but it's often safer to standardize missing values.\n",
    "X = df[features].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# For numeric columns, keep NaN (CatBoost handles), or fill with sentinel if you prefer:\n",
    "# X[num_features] = X[num_features].astype(float).fillna(np.nan)\n",
    "\n",
    "# For categorical columns: convert to string and set explicit \"missing\"\n",
    "for c in cat_features:\n",
    "    X[c] = X[c].astype(\"object\").fillna(\"missing\")\n",
    "\n",
    "# ---------- 3) Class-capped downsampling to keep training manageable ----------\n",
    "# Keep up to `cap_per_class` rows per class (keeps all minority, trims heavy majority)\n",
    "cap_per_class = 8000  # adjust based on your RAM/time budget\n",
    "np.random.seed(42)\n",
    "\n",
    "tmp = X.copy()\n",
    "tmp[target_col] = y.values\n",
    "\n",
    "# Shuffle within each class and take head(cap)\n",
    "tmp[\"_rand\"] = np.random.rand(len(tmp))\n",
    "tmp = tmp.sort_values([target_col, \"_rand\"])\n",
    "\n",
    "# groupby().head() is efficient and keeps all classes <= cap\n",
    "tmp_small = tmp.groupby(target_col, group_keys=False).head(cap_per_class).drop(columns=\"_rand\")\n",
    "\n",
    "X_small = tmp_small[features].reset_index(drop=True)\n",
    "y_small = tmp_small[target_col].reset_index(drop=True)\n",
    "\n",
    "print(f\"Downsampled from {len(df):,} to {len(X_small):,} rows \"\n",
    "      f\"({y_small.nunique()} classes).\")\n",
    "\n",
    "# ---------- 4) Train/Valid split (stratified) ----------\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "train_idx, val_idx = next(sss.split(X_small, y_small))\n",
    "\n",
    "X_train, X_val = X_small.iloc[train_idx], X_small.iloc[val_idx]\n",
    "y_train, y_val = y_small.iloc[train_idx], y_small.iloc[val_idx]\n",
    "\n",
    "# CatBoost needs indices (not names) for categorical features\n",
    "cat_indices = [X_train.columns.get_loc(c) for c in cat_features]\n",
    "\n",
    "train_pool = Pool(X_train, label=y_train, cat_features=cat_indices)\n",
    "val_pool   = Pool(X_val,   label=y_val,   cat_features=cat_indices)\n",
    "\n",
    "# ---------- 5) Train CatBoost ----------\n",
    "# Tip: If you have a CUDA GPU, set task_type='GPU' and maybe increase iterations.\n",
    "params = dict(\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"MultiClass\",\n",
    "    learning_rate=0.1,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3.0,\n",
    "    iterations=1500,\n",
    "    random_seed=42,\n",
    "    early_stopping_rounds=100,\n",
    "    task_type=\"CPU\",              # change to \"GPU\" if available\n",
    "    verbose=200,\n",
    "    allow_writing_files=False,    # keep workspace clean\n",
    ")\n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(train_pool, eval_set=val_pool, use_best_model=True)\n",
    "\n",
    "# ---------- 6) Metrics: Accuracy + MAP@5 ----------\n",
    "def apk(actual, predicted, k=5):\n",
    "    \"\"\"Average precision at k for a single sample.\"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    # If actual is a scalar (multiclass), wrap as list\n",
    "    actual_set = {actual} if not isinstance(actual, (list, set, tuple)) else set(actual)\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual_set and p is not None:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "            # For single-label multiclass, we can break after first hit\n",
    "            break\n",
    "    return score\n",
    "\n",
    "def mapk(actuals, preds_topk, k=5):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actuals, preds_topk)])\n",
    "\n",
    "# Predict probabilities then take top-5 classes\n",
    "proba = model.predict_proba(val_pool)\n",
    "top5 = np.argsort(-proba, axis=1)[:, :5]  # top-5 class indices according to model's internal class order\n",
    "\n",
    "# CatBoost's class order matches sorted(unique(y_train)) internally; we need to map to original labels:\n",
    "classes = model.classes_  # array of labels in the model order\n",
    "top5_labels = classes[top5]\n",
    "\n",
    "# Accuracy (top-1)\n",
    "pred1_labels = top5_labels[:, 0]\n",
    "acc = accuracy_score(y_val, pred1_labels)\n",
    "\n",
    "# MAP@5\n",
    "map5 = mapk(y_val.values, top5_labels, k=5)\n",
    "\n",
    "print(f\"\\nValidation Accuracy (CatBoost): {acc:.4f}\")\n",
    "print(f\"Validation MAP@5 (CatBoost):   {map5:.4f}\")\n",
    "\n",
    "# ---------- 7) Feature importance ----------\n",
    "imp_values = model.get_feature_importance(type=\"PredictionValuesChange\")\n",
    "imp_df = (\n",
    "    pd.DataFrame({\"feature\": X_train.columns, \"importance\": imp_values})\n",
    "      .sort_values(\"importance\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "print(\"\\nTop 20 feature importances:\")\n",
    "display(imp_df.head(20))\n",
    "\n",
    "# (Optional) Save model\n",
    "# model.save_model(\"catboost_multiclass.cbm\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

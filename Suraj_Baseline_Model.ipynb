{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "site_name",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "posa_continent",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_location_country",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_location_region",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_location_city",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "orig_destination_distance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "user_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_mobile",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_package",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "channel",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "srch_ci",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "srch_co",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "srch_adults_cnt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "srch_children_cnt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "srch_rm_cnt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "srch_destination_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "srch_destination_type_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_booking",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cnt",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hotel_continent",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hotel_country",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hotel_market",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hotel_cluster",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "b8000266-7460-490b-9d39-a3826ef82483",
       "rows": [
        [
         "0",
         "2014-08-11 07:46:59",
         "2",
         "3",
         "66",
         "348",
         "48862",
         "2234.2641",
         "12",
         "0",
         "1",
         "9",
         "2014-08-27",
         "2014-08-31",
         "2",
         "0",
         "1",
         "8250",
         "1",
         "0",
         "3",
         "2",
         "50",
         "628",
         "1"
        ],
        [
         "1",
         "2014-08-11 08:22:12",
         "2",
         "3",
         "66",
         "348",
         "48862",
         "2234.2641",
         "12",
         "0",
         "1",
         "9",
         "2014-08-29",
         "2014-09-02",
         "2",
         "0",
         "1",
         "8250",
         "1",
         "1",
         "1",
         "2",
         "50",
         "628",
         "1"
        ],
        [
         "2",
         "2014-02-27 18:01:32",
         "2",
         "3",
         "66",
         "318",
         "52078",
         null,
         "756",
         "0",
         "1",
         "4",
         "2014-04-18",
         "2014-04-20",
         "2",
         "0",
         "1",
         "8291",
         "1",
         "1",
         "1",
         "2",
         "50",
         "191",
         "2"
        ],
        [
         "3",
         "2013-06-15 15:38:05",
         "30",
         "4",
         "195",
         "548",
         "56440",
         null,
         "1048",
         "0",
         "1",
         "9",
         "2013-09-06",
         "2013-09-14",
         "2",
         "0",
         "1",
         "1385",
         "1",
         "1",
         "1",
         "0",
         "185",
         "185",
         "58"
        ],
        [
         "4",
         "2014-11-23 18:02:20",
         "30",
         "4",
         "195",
         "991",
         "47725",
         null,
         "1048",
         "0",
         "0",
         "9",
         "2015-06-26",
         "2015-06-28",
         "2",
         "0",
         "1",
         "8803",
         "1",
         "1",
         "1",
         "3",
         "151",
         "69",
         "36"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>...</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-02-27 18:01:32</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>318</td>\n",
       "      <td>52078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8291</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-06-15 15:38:05</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>195</td>\n",
       "      <td>548</td>\n",
       "      <td>56440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1048</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1385</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-11-23 18:02:20</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>195</td>\n",
       "      <td>991</td>\n",
       "      <td>47725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1048</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8803</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>151</td>\n",
       "      <td>69</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  site_name  posa_continent  user_location_country   \n",
       "0  2014-08-11 07:46:59          2               3                     66  \\\n",
       "1  2014-08-11 08:22:12          2               3                     66   \n",
       "2  2014-02-27 18:01:32          2               3                     66   \n",
       "3  2013-06-15 15:38:05         30               4                    195   \n",
       "4  2014-11-23 18:02:20         30               4                    195   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance   \n",
       "0                   348               48862                  2234.2641  \\\n",
       "1                   348               48862                  2234.2641   \n",
       "2                   318               52078                        NaN   \n",
       "3                   548               56440                        NaN   \n",
       "4                   991               47725                        NaN   \n",
       "\n",
       "   user_id  is_mobile  is_package  ...  srch_children_cnt srch_rm_cnt   \n",
       "0       12          0           1  ...                  0           1  \\\n",
       "1       12          0           1  ...                  0           1   \n",
       "2      756          0           1  ...                  0           1   \n",
       "3     1048          0           1  ...                  0           1   \n",
       "4     1048          0           0  ...                  0           1   \n",
       "\n",
       "  srch_destination_id  srch_destination_type_id  is_booking  cnt   \n",
       "0                8250                         1           0    3  \\\n",
       "1                8250                         1           1    1   \n",
       "2                8291                         1           1    1   \n",
       "3                1385                         1           1    1   \n",
       "4                8803                         1           1    1   \n",
       "\n",
       "   hotel_continent  hotel_country  hotel_market  hotel_cluster  \n",
       "0                2             50           628              1  \n",
       "1                2             50           628              1  \n",
       "2                2             50           191              2  \n",
       "3                0            185           185             58  \n",
       "4                3            151            69             36  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the train data\n",
    "df = pd.read_csv(\"/Users/surajsharma/Desktop/AIPM_Bootcamp/Group-3-Expedia-Hotel-Recommendation/data/train_bookings_1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000001 entries, 0 to 1000000\n",
      "Data columns (total 24 columns):\n",
      " #   Column                     Non-Null Count    Dtype  \n",
      "---  ------                     --------------    -----  \n",
      " 0   date_time                  1000001 non-null  object \n",
      " 1   site_name                  1000001 non-null  int64  \n",
      " 2   posa_continent             1000001 non-null  int64  \n",
      " 3   user_location_country      1000001 non-null  int64  \n",
      " 4   user_location_region       1000001 non-null  int64  \n",
      " 5   user_location_city         1000001 non-null  int64  \n",
      " 6   orig_destination_distance  661222 non-null   float64\n",
      " 7   user_id                    1000001 non-null  int64  \n",
      " 8   is_mobile                  1000001 non-null  int64  \n",
      " 9   is_package                 1000001 non-null  int64  \n",
      " 10  channel                    1000001 non-null  int64  \n",
      " 11  srch_ci                    1000001 non-null  object \n",
      " 12  srch_co                    1000001 non-null  object \n",
      " 13  srch_adults_cnt            1000001 non-null  int64  \n",
      " 14  srch_children_cnt          1000001 non-null  int64  \n",
      " 15  srch_rm_cnt                1000001 non-null  int64  \n",
      " 16  srch_destination_id        1000001 non-null  int64  \n",
      " 17  srch_destination_type_id   1000001 non-null  int64  \n",
      " 18  is_booking                 1000001 non-null  int64  \n",
      " 19  cnt                        1000001 non-null  int64  \n",
      " 20  hotel_continent            1000001 non-null  int64  \n",
      " 21  hotel_country              1000001 non-null  int64  \n",
      " 22  hotel_market               1000001 non-null  int64  \n",
      " 23  hotel_cluster              1000001 non-null  int64  \n",
      "dtypes: float64(1), int64(20), object(3)\n",
      "memory usage: 183.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f7d68b6f-8d0c-4cca-949a-4f511b13f9d8",
       "rows": [
        [
         "date_time",
         "0"
        ],
        [
         "site_name",
         "0"
        ],
        [
         "posa_continent",
         "0"
        ],
        [
         "user_location_country",
         "0"
        ],
        [
         "user_location_region",
         "0"
        ],
        [
         "user_location_city",
         "0"
        ],
        [
         "orig_destination_distance",
         "338779"
        ],
        [
         "user_id",
         "0"
        ],
        [
         "is_mobile",
         "0"
        ],
        [
         "is_package",
         "0"
        ],
        [
         "channel",
         "0"
        ],
        [
         "srch_ci",
         "0"
        ],
        [
         "srch_co",
         "0"
        ],
        [
         "srch_adults_cnt",
         "0"
        ],
        [
         "srch_children_cnt",
         "0"
        ],
        [
         "srch_rm_cnt",
         "0"
        ],
        [
         "srch_destination_id",
         "0"
        ],
        [
         "srch_destination_type_id",
         "0"
        ],
        [
         "is_booking",
         "0"
        ],
        [
         "cnt",
         "0"
        ],
        [
         "hotel_continent",
         "0"
        ],
        [
         "hotel_country",
         "0"
        ],
        [
         "hotel_market",
         "0"
        ],
        [
         "hotel_cluster",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 24
       }
      },
      "text/plain": [
       "date_time                         0\n",
       "site_name                         0\n",
       "posa_continent                    0\n",
       "user_location_country             0\n",
       "user_location_region              0\n",
       "user_location_city                0\n",
       "orig_destination_distance    338779\n",
       "user_id                           0\n",
       "is_mobile                         0\n",
       "is_package                        0\n",
       "channel                           0\n",
       "srch_ci                           0\n",
       "srch_co                           0\n",
       "srch_adults_cnt                   0\n",
       "srch_children_cnt                 0\n",
       "srch_rm_cnt                       0\n",
       "srch_destination_id               0\n",
       "srch_destination_type_id          0\n",
       "is_booking                        0\n",
       "cnt                               0\n",
       "hotel_continent                   0\n",
       "hotel_country                     0\n",
       "hotel_market                      0\n",
       "hotel_cluster                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ddf99a13-c7f7-47d9-8502-c6ddd9aa733d",
       "rows": [
        [
         "date_time",
         "988343"
        ],
        [
         "site_name",
         "43"
        ],
        [
         "posa_continent",
         "5"
        ],
        [
         "user_location_country",
         "227"
        ],
        [
         "user_location_region",
         "904"
        ],
        [
         "user_location_city",
         "24512"
        ],
        [
         "orig_destination_distance",
         "523677"
        ],
        [
         "user_id",
         "269624"
        ],
        [
         "is_mobile",
         "2"
        ],
        [
         "is_package",
         "2"
        ],
        [
         "channel",
         "11"
        ],
        [
         "srch_ci",
         "1104"
        ],
        [
         "srch_co",
         "1109"
        ],
        [
         "srch_adults_cnt",
         "10"
        ],
        [
         "srch_children_cnt",
         "10"
        ],
        [
         "srch_rm_cnt",
         "9"
        ],
        [
         "srch_destination_id",
         "25558"
        ],
        [
         "srch_destination_type_id",
         "9"
        ],
        [
         "is_booking",
         "2"
        ],
        [
         "cnt",
         "14"
        ],
        [
         "hotel_continent",
         "7"
        ],
        [
         "hotel_country",
         "202"
        ],
        [
         "hotel_market",
         "2076"
        ],
        [
         "hotel_cluster",
         "100"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 24
       }
      },
      "text/plain": [
       "date_time                    988343\n",
       "site_name                        43\n",
       "posa_continent                    5\n",
       "user_location_country           227\n",
       "user_location_region            904\n",
       "user_location_city            24512\n",
       "orig_destination_distance    523677\n",
       "user_id                      269624\n",
       "is_mobile                         2\n",
       "is_package                        2\n",
       "channel                          11\n",
       "srch_ci                        1104\n",
       "srch_co                        1109\n",
       "srch_adults_cnt                  10\n",
       "srch_children_cnt                10\n",
       "srch_rm_cnt                       9\n",
       "srch_destination_id           25558\n",
       "srch_destination_type_id          9\n",
       "is_booking                        2\n",
       "cnt                              14\n",
       "hotel_continent                   7\n",
       "hotel_country                   202\n",
       "hotel_market                   2076\n",
       "hotel_cluster                   100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking duplicate rows\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse only the datetime columns\n",
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df['srch_ci']   = pd.to_datetime(df['srch_ci'], errors='coerce')\n",
    "df['srch_co']   = pd.to_datetime(df['srch_co'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000001 entries, 0 to 1000000\n",
      "Data columns (total 24 columns):\n",
      " #   Column                     Non-Null Count    Dtype         \n",
      "---  ------                     --------------    -----         \n",
      " 0   date_time                  1000001 non-null  datetime64[ns]\n",
      " 1   site_name                  1000001 non-null  int64         \n",
      " 2   posa_continent             1000001 non-null  int64         \n",
      " 3   user_location_country      1000001 non-null  int64         \n",
      " 4   user_location_region       1000001 non-null  int64         \n",
      " 5   user_location_city         1000001 non-null  int64         \n",
      " 6   orig_destination_distance  661222 non-null   float64       \n",
      " 7   user_id                    1000001 non-null  int64         \n",
      " 8   is_mobile                  1000001 non-null  int64         \n",
      " 9   is_package                 1000001 non-null  int64         \n",
      " 10  channel                    1000001 non-null  int64         \n",
      " 11  srch_ci                    1000001 non-null  datetime64[ns]\n",
      " 12  srch_co                    1000001 non-null  datetime64[ns]\n",
      " 13  srch_adults_cnt            1000001 non-null  int64         \n",
      " 14  srch_children_cnt          1000001 non-null  int64         \n",
      " 15  srch_rm_cnt                1000001 non-null  int64         \n",
      " 16  srch_destination_id        1000001 non-null  int64         \n",
      " 17  srch_destination_type_id   1000001 non-null  int64         \n",
      " 18  is_booking                 1000001 non-null  int64         \n",
      " 19  cnt                        1000001 non-null  int64         \n",
      " 20  hotel_continent            1000001 non-null  int64         \n",
      " 21  hotel_country              1000001 non-null  int64         \n",
      " 22  hotel_market               1000001 non-null  int64         \n",
      " 23  hotel_cluster              1000001 non-null  int64         \n",
      "dtypes: datetime64[ns](3), float64(1), int64(20)\n",
      "memory usage: 183.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column length_of_stay\n",
    "df['length_of_stay'] = (df['srch_co'] - df['srch_ci']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_of_stay",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "42f93baf-4b61-431c-8a2e-0c8baad6a7d7",
       "rows": [
        [
         "count",
         "1000001.0"
        ],
        [
         "mean",
         "2.425104574895425"
        ],
        [
         "std",
         "2.0216500487693416"
        ],
        [
         "min",
         "-9.0"
        ],
        [
         "25%",
         "1.0"
        ],
        [
         "50%",
         "2.0"
        ],
        [
         "75%",
         "3.0"
        ],
        [
         "max",
         "33.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "count    1.000001e+06\n",
       "mean     2.425105e+00\n",
       "std      2.021650e+00\n",
       "min     -9.000000e+00\n",
       "25%      1.000000e+00\n",
       "50%      2.000000e+00\n",
       "75%      3.000000e+00\n",
       "max      3.300000e+01\n",
       "Name: length_of_stay, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length_of_stay'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  2,  8,  5,  3,  1,  6, 12, 10,  7, 15,  9, 14, 13, 22, 11, 21,\n",
       "       17, 19, 20, 18, 16, 28, 27, 24, 23, 25, 26, 30, 31, -9, 33])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length_of_stay'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from df dataframe, remove rows where length_of_stay < 0\n",
    "df = df[df['length_of_stay'] >= 0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length_of_stay'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " hotel_cluster\n",
       " 91    40385\n",
       " 48    28908\n",
       " 42    24499\n",
       " 59    22070\n",
       " 28    21108\n",
       " 16    18881\n",
       " 18    18723\n",
       " 95    18367\n",
       " 50    18213\n",
       " 82    18030\n",
       " 21    17202\n",
       " 41    16408\n",
       " 98    16327\n",
       " 64    16045\n",
       " 25    15361\n",
       " 46    15360\n",
       " 2     15127\n",
       " 9     15091\n",
       " 6     14748\n",
       " 47    14713\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many clusters? Which are most common?\n",
    "df['hotel_cluster'].nunique(), df['hotel_cluster'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target variable\n",
    "X = df.drop(columns=['hotel_cluster'])\n",
    "y = df['hotel_cluster']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,       # 20% test set\n",
    "    random_state=42,     # reproducible split\n",
    "    stratify=y           # keep same class distribution\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (800000, 24)\n",
      "Test features: (200000, 24)\n",
      "Train labels: (800000,)\n",
      "Test labels: (200000,)\n"
     ]
    }
   ],
   "source": [
    "# verify the shape of the splits\n",
    "print(\"Train features:\", X_train.shape)\n",
    "print(\"Test features:\", X_test.shape)\n",
    "print(\"Train labels:\", y_train.shape)\n",
    "print(\"Test labels:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1) Drop datetime columns\n",
    "drop_cols = ['date_time', 'srch_ci', 'srch_co']\n",
    "X_train_ = X_train.drop(columns=drop_cols)\n",
    "X_test_  = X_test.drop(columns=drop_cols)\n",
    "\n",
    "# 2) Handle missing values\n",
    "X_train_ = X_train_.fillna(-1)\n",
    "X_test_  = X_test_.fillna(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression without scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/surajsharma/Desktop/AIPM_Bootcamp/Group-3-Expedia-Hotel-Recommendation/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=500, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Train Logistic Regression\n",
    "model = LogisticRegression(max_iter=500, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.04374\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1298\n",
      "           1       0.00      0.00      0.00      2541\n",
      "           2       0.00      0.00      0.00      3025\n",
      "           3       0.00      0.00      0.00       826\n",
      "           4       0.00      0.00      0.00      2390\n",
      "           5       0.00      0.00      0.00      2866\n",
      "           6       0.00      0.00      0.00      2950\n",
      "           7       0.00      0.00      0.00      2331\n",
      "           8       0.00      0.00      0.00      1470\n",
      "           9       0.00      0.00      0.00      3018\n",
      "          10       0.00      0.00      0.00      2081\n",
      "          11       0.00      0.00      0.00      1868\n",
      "          12       0.00      0.00      0.00      1081\n",
      "          13       0.00      0.00      0.00      2880\n",
      "          14       0.00      0.00      0.00      1040\n",
      "          15       0.00      0.00      0.00      2623\n",
      "          16       0.00      0.00      0.00      3776\n",
      "          17       0.00      0.00      0.00      1401\n",
      "          18       0.00      0.00      0.00      3745\n",
      "          19       0.00      0.00      0.00      2118\n",
      "          20       0.00      0.00      0.00       859\n",
      "          21       0.00      0.00      0.00      3441\n",
      "          22       0.00      0.00      0.00      1467\n",
      "          23       0.00      0.00      0.00      1087\n",
      "          24       0.00      0.00      0.00       824\n",
      "          25       0.00      0.00      0.00      3072\n",
      "          26       0.00      0.00      0.00      1102\n",
      "          27       0.00      0.00      0.00       172\n",
      "          28       0.00      0.00      0.00      4222\n",
      "          29       0.00      0.00      0.00      2328\n",
      "          30       0.00      0.00      0.00      1870\n",
      "          31       0.00      0.00      0.00       806\n",
      "          32       0.00      0.00      0.00      2805\n",
      "          33       0.00      0.00      0.00      2557\n",
      "          34       0.00      0.00      0.00      1270\n",
      "          35       0.00      0.00      0.00       480\n",
      "          36       0.03      0.00      0.00      2680\n",
      "          37       0.00      0.00      0.00      2679\n",
      "          38       0.00      0.00      0.00      1094\n",
      "          39       0.00      0.00      0.00      2468\n",
      "          40       0.00      0.00      0.00      2037\n",
      "          41       0.00      0.00      0.00      3282\n",
      "          42       0.00      0.00      0.00      4900\n",
      "          43       0.08      0.00      0.00      2160\n",
      "          44       0.00      0.00      0.00       731\n",
      "          45       0.00      0.00      0.00      1201\n",
      "          46       0.04      0.00      0.01      3072\n",
      "          47       0.00      0.00      0.00      2943\n",
      "          48       0.00      0.00      0.00      5782\n",
      "          49       0.00      0.00      0.00      1573\n",
      "          50       0.00      0.00      0.00      3643\n",
      "          51       0.00      0.00      0.00      2045\n",
      "          52       0.00      0.00      0.00       558\n",
      "          53       0.00      0.00      0.00       342\n",
      "          54       0.00      0.00      0.00      1420\n",
      "          55       0.00      0.00      0.00      2346\n",
      "          56       0.00      0.00      0.00      1915\n",
      "          57       0.00      0.00      0.00       949\n",
      "          58       0.00      0.00      0.00      2087\n",
      "          59       0.04      0.02      0.02      4414\n",
      "          60       0.00      0.00      0.00       545\n",
      "          61       0.00      0.00      0.00      1841\n",
      "          62       0.03      0.00      0.00      2718\n",
      "          63       0.00      0.00      0.00      1005\n",
      "          64       0.05      0.21      0.08      3209\n",
      "          65       0.00      0.00      0.00      1414\n",
      "          66       0.00      0.00      0.00       636\n",
      "          67       0.00      0.00      0.00      1484\n",
      "          68       0.00      0.00      0.00      2836\n",
      "          69       0.00      0.00      0.00      1238\n",
      "          70       0.00      0.00      0.00      2454\n",
      "          71       0.00      0.00      0.00       620\n",
      "          72       0.00      0.00      0.00      2883\n",
      "          73       0.00      0.00      0.00       969\n",
      "          74       0.00      0.00      0.00       159\n",
      "          75       0.00      0.00      0.00       750\n",
      "          76       0.00      0.00      0.00      1288\n",
      "          77       0.00      0.00      0.00      2641\n",
      "          78       0.00      0.00      0.00      1696\n",
      "          79       0.00      0.00      0.00      1421\n",
      "          80       0.00      0.00      0.00       517\n",
      "          81       0.00      0.00      0.00      2052\n",
      "          82       0.04      0.04      0.04      3606\n",
      "          83       0.00      0.00      0.00      2211\n",
      "          84       0.00      0.00      0.00       695\n",
      "          85       0.00      0.00      0.00      1574\n",
      "          86       0.00      0.00      0.00       498\n",
      "          87       0.00      0.00      0.00       419\n",
      "          88       0.00      0.00      0.00       475\n",
      "          89       0.00      0.00      0.00      1007\n",
      "          90       0.00      0.00      0.00      1598\n",
      "          91       0.04      0.97      0.08      8077\n",
      "          92       0.00      0.00      0.00       420\n",
      "          93       0.00      0.00      0.00       604\n",
      "          94       0.00      0.00      0.00      1835\n",
      "          95       0.00      0.00      0.00      3673\n",
      "          96       0.00      0.00      0.00      1110\n",
      "          97       0.00      0.00      0.00      1939\n",
      "          98       0.00      0.00      0.00      3265\n",
      "          99       0.00      0.00      0.00      2607\n",
      "\n",
      "    accuracy                           0.04    200000\n",
      "   macro avg       0.00      0.01      0.00    200000\n",
      "weighted avg       0.01      0.04      0.01    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4) Predict\n",
    "y_pred = model.predict(X_test_)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# 5) Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression after scaling the features and introducing hyperparameter solver='saga'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_)\n",
    "X_test_scaled  = scaler.transform(X_test_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200, multi_class=&#x27;multinomial&#x27;, n_jobs=-1,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, multi_class=&#x27;multinomial&#x27;, n_jobs=-1,\n",
       "                   random_state=42, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200, multi_class='multinomial', n_jobs=-1,\n",
       "                   random_state=42, solver='saga')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    solver=\"saga\",          # good for large, sparse-ish data\n",
    "    multi_class=\"multinomial\",\n",
    "    max_iter=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "logreg.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.01      0.01      1298\n",
      "           1       0.08      0.36      0.13      2541\n",
      "           2       0.06      0.04      0.05      3025\n",
      "           3       0.00      0.00      0.00       826\n",
      "           4       0.00      0.00      0.00      2390\n",
      "           5       0.05      0.02      0.03      2866\n",
      "           6       0.00      0.00      0.00      2950\n",
      "           7       0.01      0.00      0.00      2331\n",
      "           8       0.11      0.01      0.02      1470\n",
      "           9       0.04      0.06      0.04      3018\n",
      "          10       0.03      0.00      0.00      2081\n",
      "          11       0.00      0.00      0.00      1868\n",
      "          12       0.06      0.09      0.07      1081\n",
      "          13       0.00      0.00      0.00      2880\n",
      "          14       0.00      0.00      0.00      1040\n",
      "          15       0.04      0.01      0.01      2623\n",
      "          16       0.03      0.00      0.00      3776\n",
      "          17       0.00      0.00      0.00      1401\n",
      "          18       0.00      0.00      0.00      3745\n",
      "          19       0.00      0.00      0.00      2118\n",
      "          20       0.00      0.00      0.00       859\n",
      "          21       0.05      0.00      0.00      3441\n",
      "          22       0.06      0.00      0.01      1467\n",
      "          23       0.00      0.00      0.00      1087\n",
      "          24       0.00      0.00      0.00       824\n",
      "          25       0.06      0.02      0.03      3072\n",
      "          26       0.03      0.00      0.00      1102\n",
      "          27       0.00      0.00      0.00       172\n",
      "          28       0.05      0.06      0.05      4222\n",
      "          29       0.05      0.00      0.01      2328\n",
      "          30       0.10      0.00      0.00      1870\n",
      "          31       0.00      0.00      0.00       806\n",
      "          32       0.06      0.00      0.00      2805\n",
      "          33       0.00      0.00      0.00      2557\n",
      "          34       0.00      0.00      0.00      1270\n",
      "          35       0.00      0.00      0.00       480\n",
      "          36       0.07      0.04      0.05      2680\n",
      "          37       0.05      0.00      0.00      2679\n",
      "          38       0.00      0.00      0.00      1094\n",
      "          39       0.17      0.00      0.00      2468\n",
      "          40       0.00      0.00      0.00      2037\n",
      "          41       0.03      0.00      0.01      3282\n",
      "          42       0.02      0.00      0.01      4900\n",
      "          43       0.03      0.03      0.03      2160\n",
      "          44       0.00      0.00      0.00       731\n",
      "          45       0.11      0.01      0.01      1201\n",
      "          46       0.07      0.07      0.07      3072\n",
      "          47       0.00      0.00      0.00      2943\n",
      "          48       0.03      0.01      0.01      5782\n",
      "          49       0.00      0.00      0.00      1573\n",
      "          50       0.00      0.00      0.00      3643\n",
      "          51       0.00      0.00      0.00      2045\n",
      "          52       0.00      0.00      0.00       558\n",
      "          53       0.00      0.00      0.00       342\n",
      "          54       0.00      0.00      0.00      1420\n",
      "          55       0.06      0.02      0.03      2346\n",
      "          56       0.05      0.01      0.01      1915\n",
      "          57       0.00      0.00      0.00       949\n",
      "          58       0.03      0.00      0.00      2087\n",
      "          59       0.06      0.16      0.09      4414\n",
      "          60       0.00      0.00      0.00       545\n",
      "          61       0.00      0.00      0.00      1841\n",
      "          62       0.05      0.04      0.05      2718\n",
      "          63       0.09      0.02      0.03      1005\n",
      "          64       0.07      0.29      0.11      3209\n",
      "          65       0.17      0.79      0.28      1414\n",
      "          66       0.10      0.01      0.02       636\n",
      "          67       0.08      0.01      0.02      1484\n",
      "          68       0.00      0.00      0.00      2836\n",
      "          69       0.00      0.00      0.00      1238\n",
      "          70       0.00      0.00      0.00      2454\n",
      "          71       0.07      0.01      0.02       620\n",
      "          72       0.00      0.00      0.00      2883\n",
      "          73       0.00      0.00      0.00       969\n",
      "          74       0.00      0.00      0.00       159\n",
      "          75       0.00      0.00      0.00       750\n",
      "          76       0.00      0.00      0.00      1288\n",
      "          77       0.00      0.00      0.00      2641\n",
      "          78       0.00      0.00      0.00      1696\n",
      "          79       0.00      0.00      0.00      1421\n",
      "          80       0.00      0.00      0.00       517\n",
      "          81       0.07      0.03      0.04      2052\n",
      "          82       0.08      0.39      0.13      3606\n",
      "          83       0.00      0.00      0.00      2211\n",
      "          84       0.00      0.00      0.00       695\n",
      "          85       0.00      0.00      0.00      1574\n",
      "          86       0.00      0.00      0.00       498\n",
      "          87       0.00      0.00      0.00       419\n",
      "          88       0.00      0.00      0.00       475\n",
      "          89       0.00      0.00      0.00      1007\n",
      "          90       0.00      0.00      0.00      1598\n",
      "          91       0.07      0.85      0.13      8077\n",
      "          92       0.00      0.00      0.00       420\n",
      "          93       0.00      0.00      0.00       604\n",
      "          94       0.00      0.00      0.00      1835\n",
      "          95       0.05      0.06      0.05      3673\n",
      "          96       0.00      0.00      0.00      1110\n",
      "          97       0.03      0.00      0.01      1939\n",
      "          98       0.05      0.04      0.04      3265\n",
      "          99       0.06      0.00      0.00      2607\n",
      "\n",
      "    accuracy                           0.07    200000\n",
      "   macro avg       0.03      0.04      0.02    200000\n",
      "weighted avg       0.03      0.07      0.03    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = logreg.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (This time we also drop other non-relevant features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 841.2169768641178\n",
      "R²: 0.002472509922123889\n",
      "Rounded Accuracy: 0.01898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 1) Drop datetime cols\n",
    "drop_cols = [\n",
    "    'date_time', 'srch_ci', 'srch_co',\n",
    "    'cnt', 'is_booking', 'user_id',\n",
    "    'srch_destination_id', 'srch_destination_type_id',\n",
    "    'hotel_country', 'hotel_market'\n",
    "]\n",
    "\n",
    "X_train_lr = X_train.drop(columns=drop_cols).fillna(-1)\n",
    "X_test_lr  = X_test.drop(columns=drop_cols).fillna(-1)\n",
    "\n",
    "# 2) Train Linear Regression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train_lr, y_train)\n",
    "\n",
    "# 3) Predict (continuous values)\n",
    "y_pred_cont = linreg.predict(X_test_lr)\n",
    "\n",
    "# 4) Round to nearest int to compare with hotel_cluster\n",
    "y_pred_round = np.rint(y_pred_cont).astype(int)\n",
    "\n",
    "# 5) Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred_cont)\n",
    "r2  = r2_score(y_test, y_pred_cont)\n",
    "acc = (y_pred_round == y_test).mean()\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R²:\", r2)\n",
    "print(\"Rounded Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: It seems Regression is a no-go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    'date_time', 'srch_ci', 'srch_co',\n",
    "    'cnt', 'is_booking', 'user_id',\n",
    "    'srch_destination_id', 'srch_destination_type_id',\n",
    "    'hotel_country', 'hotel_market'\n",
    "]\n",
    "\n",
    "X_train_rf = X_train.drop(columns=drop_cols).fillna(-1)\n",
    "X_test_rf  = X_test.drop(columns=drop_cols).fillna(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=15, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=15, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=15, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,   # number of trees\n",
    "    max_depth=15,       # limit depth to avoid huge trees\n",
    "    random_state=42,\n",
    "    n_jobs=-1           # use all CPU cores\n",
    ")\n",
    "rf.fit(X_train_rf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.18      0.17      1298\n",
      "           1       0.14      0.54      0.22      2541\n",
      "           2       0.09      0.07      0.08      3025\n",
      "           3       0.15      0.01      0.01       826\n",
      "           4       0.14      0.02      0.04      2390\n",
      "           5       0.09      0.03      0.05      2866\n",
      "           6       0.21      0.02      0.03      2950\n",
      "           7       0.10      0.00      0.00      2331\n",
      "           8       0.19      0.10      0.13      1470\n",
      "           9       0.12      0.02      0.04      3018\n",
      "          10       0.25      0.02      0.03      2081\n",
      "          11       0.10      0.01      0.02      1868\n",
      "          12       0.12      0.21      0.15      1081\n",
      "          13       0.11      0.01      0.01      2880\n",
      "          14       0.12      0.00      0.01      1040\n",
      "          15       0.17      0.01      0.02      2623\n",
      "          16       0.17      0.01      0.02      3776\n",
      "          17       0.18      0.01      0.01      1401\n",
      "          18       0.10      0.01      0.01      3745\n",
      "          19       0.12      0.01      0.03      2118\n",
      "          20       0.16      0.02      0.04       859\n",
      "          21       0.13      0.01      0.02      3441\n",
      "          22       0.09      0.07      0.08      1467\n",
      "          23       0.12      0.00      0.01      1087\n",
      "          24       0.18      0.02      0.03       824\n",
      "          25       0.07      0.03      0.05      3072\n",
      "          26       0.23      0.05      0.09      1102\n",
      "          27       0.11      0.01      0.02       172\n",
      "          28       0.09      0.04      0.05      4222\n",
      "          29       0.07      0.03      0.04      2328\n",
      "          30       0.09      0.04      0.06      1870\n",
      "          31       0.24      0.00      0.01       806\n",
      "          32       0.11      0.01      0.01      2805\n",
      "          33       0.17      0.01      0.02      2557\n",
      "          34       0.11      0.01      0.03      1270\n",
      "          35       0.27      0.02      0.04       480\n",
      "          36       0.09      0.15      0.11      2680\n",
      "          37       0.11      0.01      0.01      2679\n",
      "          38       0.19      0.09      0.12      1094\n",
      "          39       0.14      0.02      0.03      2468\n",
      "          40       0.20      0.01      0.01      2037\n",
      "          41       0.07      0.03      0.04      3282\n",
      "          42       0.09      0.01      0.02      4900\n",
      "          43       0.12      0.01      0.02      2160\n",
      "          44       0.16      0.01      0.02       731\n",
      "          45       0.24      0.08      0.12      1201\n",
      "          46       0.09      0.26      0.13      3072\n",
      "          47       0.13      0.00      0.01      2943\n",
      "          48       0.11      0.02      0.03      5782\n",
      "          49       0.20      0.01      0.02      1573\n",
      "          50       0.12      0.01      0.02      3643\n",
      "          51       0.16      0.00      0.01      2045\n",
      "          52       0.22      0.02      0.04       558\n",
      "          53       0.16      0.01      0.02       342\n",
      "          54       0.22      0.09      0.13      1420\n",
      "          55       0.09      0.03      0.05      2346\n",
      "          56       0.14      0.12      0.13      1915\n",
      "          57       0.14      0.04      0.07       949\n",
      "          58       0.11      0.02      0.03      2087\n",
      "          59       0.08      0.09      0.09      4414\n",
      "          60       0.22      0.02      0.04       545\n",
      "          61       0.15      0.03      0.06      1841\n",
      "          62       0.08      0.09      0.08      2718\n",
      "          63       0.14      0.11      0.12      1005\n",
      "          64       0.08      0.33      0.13      3209\n",
      "          65       0.23      0.90      0.37      1414\n",
      "          66       0.25      0.04      0.07       636\n",
      "          67       0.11      0.03      0.05      1484\n",
      "          68       0.15      0.02      0.03      2836\n",
      "          69       0.16      0.01      0.01      1238\n",
      "          70       0.08      0.04      0.05      2454\n",
      "          71       0.21      0.10      0.14       620\n",
      "          72       0.07      0.00      0.00      2883\n",
      "          73       0.26      0.01      0.03       969\n",
      "          74       0.25      0.14      0.18       159\n",
      "          75       0.18      0.01      0.02       750\n",
      "          76       0.19      0.00      0.01      1288\n",
      "          77       0.17      0.02      0.03      2641\n",
      "          78       0.11      0.02      0.03      1696\n",
      "          79       0.14      0.01      0.02      1421\n",
      "          80       0.17      0.03      0.05       517\n",
      "          81       0.09      0.11      0.10      2052\n",
      "          82       0.08      0.38      0.13      3606\n",
      "          83       0.14      0.01      0.02      2211\n",
      "          84       0.00      0.00      0.00       695\n",
      "          85       0.12      0.02      0.03      1574\n",
      "          86       0.25      0.01      0.01       498\n",
      "          87       0.29      0.01      0.02       419\n",
      "          88       0.00      0.00      0.00       475\n",
      "          89       0.05      0.00      0.00      1007\n",
      "          90       0.12      0.02      0.03      1598\n",
      "          91       0.08      0.87      0.14      8077\n",
      "          92       0.34      0.06      0.10       420\n",
      "          93       0.31      0.01      0.01       604\n",
      "          94       0.32      0.00      0.01      1835\n",
      "          95       0.12      0.05      0.07      3673\n",
      "          96       0.33      0.01      0.03      1110\n",
      "          97       0.15      0.01      0.02      1939\n",
      "          98       0.10      0.07      0.08      3265\n",
      "          99       0.16      0.02      0.04      2607\n",
      "\n",
      "    accuracy                           0.09    200000\n",
      "   macro avg       0.15      0.06      0.05    200000\n",
      "weighted avg       0.13      0.09      0.05    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = rf.predict(X_test_rf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests with Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feat_importances = pd.DataFrame({\n",
    "    \"feature\": X_train_rf.columns,\n",
    "    \"importance\": rf.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_n = 20\n",
    "top_feats = feat_importances.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "bars = plt.barh(top_feats[\"feature\"], top_feats[\"importance\"])\n",
    "plt.gca().invert_yaxis()  # highest on top\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.title(f\"Top {top_n} Feature Importances - Random Forest\")\n",
    "\n",
    "# Add text labels\n",
    "for bar, imp in zip(bars, top_feats[\"importance\"]):\n",
    "    plt.text(\n",
    "        bar.get_width(), \n",
    "        bar.get_y() + bar.get_height()/2,\n",
    "        f\"{imp:.3f}\",   # format to 3 decimals\n",
    "        va=\"center\", ha=\"left\"\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fallback dataframe of df before I modify it further\n",
    "df_fallback = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Logistic Regression for a bit, this time with OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns for OHE\n",
    "categorical_cols = [\n",
    "    'posa_continent',   # 5\n",
    "    'hotel_continent',  # 7\n",
    "    'channel',          # 11\n",
    "    'is_package',       # 2\n",
    "    'is_mobile'         # 2\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "categorical_cols = ['posa_continent','hotel_continent','channel','is_package','is_mobile']\n",
    "numeric_cols = [c for c in X_train_lr.columns if c not in categorical_cols]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    [\n",
    "        ('cat', Pipeline([\n",
    "            ('imp', SimpleImputer(strategy='most_frequent')),\n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore',\n",
    "                                  sparse_output=True,\n",
    "                                  dtype='float32'))\n",
    "        ]), categorical_cols),\n",
    "        ('num', Pipeline([\n",
    "            ('imp', SimpleImputer(strategy='median')),\n",
    "            ('sc', StandardScaler(with_mean=False))\n",
    "        ]), numeric_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "sgd_logreg = SGDClassifier(\n",
    "    loss='log_loss',     # logistic regression\n",
    "    penalty='l2',\n",
    "    alpha=1e-4,\n",
    "    early_stopping=True, # fast + prevents overfitting\n",
    "    n_iter_no_change=3,\n",
    "    max_iter=1000,\n",
    "    tol=1e-3,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pre&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imp&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;ohe&#x27;,\n",
       "                                                                   OneHotEncoder(dtype=&#x27;float32&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;posa_continent&#x27;,\n",
       "                                                   &#x27;hotel_continent&#x27;, &#x27;channel&#x27;,\n",
       "                                                   &#x27;is_package&#x27;, &#x27;is_mobile&#x27;]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imp&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;sc&#x27;,\n",
       "                                                                   StandardScaler(with_mean=False))]),\n",
       "                                                  [&#x27;site_name&#x27;,\n",
       "                                                   &#x27;user_location_country&#x27;,\n",
       "                                                   &#x27;user_location_region&#x27;,\n",
       "                                                   &#x27;user_location_city&#x27;,\n",
       "                                                   &#x27;orig_destination_distance&#x27;,\n",
       "                                                   &#x27;srch_adults_cnt&#x27;,\n",
       "                                                   &#x27;srch_children_cnt&#x27;,\n",
       "                                                   &#x27;srch_rm_cnt&#x27;,\n",
       "                                                   &#x27;length_of_stay&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 SGDClassifier(early_stopping=True, loss=&#x27;log_loss&#x27;,\n",
       "                               n_iter_no_change=3, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pre&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imp&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;ohe&#x27;,\n",
       "                                                                   OneHotEncoder(dtype=&#x27;float32&#x27;,\n",
       "                                                                                 handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;posa_continent&#x27;,\n",
       "                                                   &#x27;hotel_continent&#x27;, &#x27;channel&#x27;,\n",
       "                                                   &#x27;is_package&#x27;, &#x27;is_mobile&#x27;]),\n",
       "                                                 (&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imp&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;sc&#x27;,\n",
       "                                                                   StandardScaler(with_mean=False))]),\n",
       "                                                  [&#x27;site_name&#x27;,\n",
       "                                                   &#x27;user_location_country&#x27;,\n",
       "                                                   &#x27;user_location_region&#x27;,\n",
       "                                                   &#x27;user_location_city&#x27;,\n",
       "                                                   &#x27;orig_destination_distance&#x27;,\n",
       "                                                   &#x27;srch_adults_cnt&#x27;,\n",
       "                                                   &#x27;srch_children_cnt&#x27;,\n",
       "                                                   &#x27;srch_rm_cnt&#x27;,\n",
       "                                                   &#x27;length_of_stay&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 SGDClassifier(early_stopping=True, loss=&#x27;log_loss&#x27;,\n",
       "                               n_iter_no_change=3, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pre: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imp&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;ohe&#x27;,\n",
       "                                                  OneHotEncoder(dtype=&#x27;float32&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;posa_continent&#x27;, &#x27;hotel_continent&#x27;,\n",
       "                                  &#x27;channel&#x27;, &#x27;is_package&#x27;, &#x27;is_mobile&#x27;]),\n",
       "                                (&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imp&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;sc&#x27;,\n",
       "                                                  StandardScaler(with_mean=False))]),\n",
       "                                 [&#x27;site_name&#x27;, &#x27;user_location_country&#x27;,\n",
       "                                  &#x27;user_location_region&#x27;, &#x27;user_location_city&#x27;,\n",
       "                                  &#x27;orig_destination_distance&#x27;,\n",
       "                                  &#x27;srch_adults_cnt&#x27;, &#x27;srch_children_cnt&#x27;,\n",
       "                                  &#x27;srch_rm_cnt&#x27;, &#x27;length_of_stay&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;posa_continent&#x27;, &#x27;hotel_continent&#x27;, &#x27;channel&#x27;, &#x27;is_package&#x27;, &#x27;is_mobile&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(dtype=&#x27;float32&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;site_name&#x27;, &#x27;user_location_country&#x27;, &#x27;user_location_region&#x27;, &#x27;user_location_city&#x27;, &#x27;orig_destination_distance&#x27;, &#x27;srch_adults_cnt&#x27;, &#x27;srch_children_cnt&#x27;, &#x27;srch_rm_cnt&#x27;, &#x27;length_of_stay&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler(with_mean=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(early_stopping=True, loss=&#x27;log_loss&#x27;, n_iter_no_change=3,\n",
       "              random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pre',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imp',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('ohe',\n",
       "                                                                   OneHotEncoder(dtype='float32',\n",
       "                                                                                 handle_unknown='ignore'))]),\n",
       "                                                  ['posa_continent',\n",
       "                                                   'hotel_continent', 'channel',\n",
       "                                                   'is_package', 'is_mobile']),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('imp',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('sc',\n",
       "                                                                   StandardScaler(with_mean=False))]),\n",
       "                                                  ['site_name',\n",
       "                                                   'user_location_country',\n",
       "                                                   'user_location_region',\n",
       "                                                   'user_location_city',\n",
       "                                                   'orig_destination_distance',\n",
       "                                                   'srch_adults_cnt',\n",
       "                                                   'srch_children_cnt',\n",
       "                                                   'srch_rm_cnt',\n",
       "                                                   'length_of_stay'])])),\n",
       "                ('clf',\n",
       "                 SGDClassifier(early_stopping=True, loss='log_loss',\n",
       "                               n_iter_no_change=3, random_state=42))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the pipeline\n",
    "pipe = Pipeline([('pre', pre), ('clf', sgd_logreg)])\n",
    "pipe.fit(X_train_lr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = pipe.predict(X_test_lr)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducing top 5 accuracy in logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 Accuracy: 0.23025\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    return np.exp(z) / np.exp(z).sum(axis=1, keepdims=True)\n",
    "\n",
    "# Try predict_proba; if unavailable, fall back to decision_function + softmax\n",
    "try:\n",
    "    proba = pipe.predict_proba(X_test_lr)\n",
    "except AttributeError:\n",
    "    scores = pipe.decision_function(X_test_lr)   # shape: [n_samples, n_classes]\n",
    "    proba = softmax(scores)\n",
    "\n",
    "top5_idx = np.argsort(proba, axis=1)[:, -5:]     # indices of top-5 classes\n",
    "top5_hit = np.fromiter((yt in row for yt, row in zip(y_test, top5_idx)), bool)\n",
    "print(\"Top-5 Accuracy:\", top5_hit.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focusing on Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.09282\n",
      "Top-5 Accuracy: 0.28971\n"
     ]
    }
   ],
   "source": [
    "# Random Forest with Top-5 Accuracy (Baseline)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Drop irrelevant / leakage columns\n",
    "drop_cols = [\n",
    "    'date_time', 'srch_ci', 'srch_co',\n",
    "    'cnt', 'is_booking', 'user_id',\n",
    "    'srch_destination_id', 'srch_destination_type_id',\n",
    "    'hotel_country', 'hotel_market'\n",
    "]\n",
    "\n",
    "X_train_rf = X_train.drop(columns=drop_cols).fillna(-1)\n",
    "X_test_rf  = X_test.drop(columns=drop_cols).fillna(-1)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train_rf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf.predict(X_test_rf)\n",
    "print(\"Top-1 Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# --- Top-5 Accuracy ---\n",
    "proba = rf.predict_proba(X_test_rf)\n",
    "top5 = np.argsort(proba, axis=1)[:, -5:]\n",
    "top5_acc = np.mean([y in row for y, row in zip(y_test, top5)])\n",
    "print(\"Top-5 Accuracy:\", top5_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numerical values with median\n",
    "X_train['orig_destination_distance'].fillna(X_train['orig_destination_distance'].median(), inplace=True)\n",
    "X_test['orig_destination_distance'].fillna(X_train['orig_destination_distance'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log-transform to orig_destination_distance\n",
    "X_train['orig_destination_distance'] = np.log1p(X_train['orig_destination_distance'])\n",
    "X_test['orig_destination_distance'] = np.log1p(X_test['orig_destination_distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducing 4 new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure datetime (won’t hurt if already done)\n",
    "for df_ in (X_train, X_test):\n",
    "    df_['srch_ci'] = pd.to_datetime(df_['srch_ci'], errors='coerce')\n",
    "    df_['date_time'] = pd.to_datetime(df_['date_time'], errors='coerce')\n",
    "\n",
    "# 1) month of check-in  2) weekday of check-in  3) was the search on weekend?  4) days between search and check-in\n",
    "for df_ in (X_train, X_test):\n",
    "    df_['checkin_month'] = df_['srch_ci'].dt.month.fillna(-1).astype('int16')\n",
    "    df_['checkin_weekday'] = df_['srch_ci'].dt.weekday.fillna(-1).astype('int8')\n",
    "    df_['is_weekend'] = df_['date_time'].dt.weekday.ge(5).fillna(False).astype('int8')\n",
    "    df_['advance_days'] = (df_['srch_ci'] - df_['date_time']).dt.days\n",
    "    df_['advance_days'] = df_['advance_days'].fillna(-1).clip(lower=-1).astype('int16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "checkin_month",
         "rawType": "int16",
         "type": "integer"
        },
        {
         "name": "checkin_weekday",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "is_weekend",
         "rawType": "int8",
         "type": "integer"
        },
        {
         "name": "advance_days",
         "rawType": "int16",
         "type": "integer"
        }
       ],
       "ref": "db8594cc-4b51-4727-bb14-156032db1e01",
       "rows": [
        [
         "275825",
         "7",
         "3",
         "0",
         "23"
        ],
        [
         "442208",
         "5",
         "3",
         "0",
         "-1"
        ],
        [
         "844070",
         "2",
         "2",
         "0",
         "14"
        ],
        [
         "815699",
         "5",
         "6",
         "1",
         "20"
        ],
        [
         "129347",
         "5",
         "6",
         "1",
         "34"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkin_month</th>\n",
       "      <th>checkin_weekday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>advance_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275825</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442208</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844070</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815699</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129347</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        checkin_month  checkin_weekday  is_weekend  advance_days\n",
       "275825              7                3           0            23\n",
       "442208              5                3           0            -1\n",
       "844070              2                2           0            14\n",
       "815699              5                6           1            20\n",
       "129347              5                6           1            34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the new features\n",
    "X_train[['checkin_month','checkin_weekday','is_weekend','advance_days']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining model after Feature Engg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 0.16604\n",
      "Top-5 Accuracy: 0.46213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "\n",
    "# 1) Drop raw datetime columns (we've already derived features from them)\n",
    "for df_ in (X_train, X_test):\n",
    "    for c in ['srch_ci', 'srch_co', 'date_time']:\n",
    "        if c in df_.columns:\n",
    "            df_.drop(columns=c, inplace=True)\n",
    "\n",
    "# 2) Encode any remaining object/string columns to integers (simple + safe for trees)\n",
    "cat_cols = X_train.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    # make one mapping from TRAIN values; unseen in test -> -1\n",
    "    mapping = {v: i for i, v in enumerate(X_train[col].astype(str).unique())}\n",
    "    X_train[col] = X_train[col].astype(str).map(mapping).fillna(-1).astype('int32')\n",
    "    X_test[col]  = X_test[col].astype(str).map(mapping).fillna(-1).astype('int32')\n",
    "\n",
    "# 3) Fit + evaluate\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)\n",
    "\n",
    "top1 = accuracy_score(y_test, y_pred)\n",
    "top5 = top_k_accuracy_score(y_test, y_proba, k=5)\n",
    "\n",
    "print(\"Top-1 Accuracy:\", top1)\n",
    "print(\"Top-5 Accuracy:\", top5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Categorical Features\n",
    "- Frequency encoding (For high cardinality columns like user_location_city)\n",
    "- One-hot for low cardinality features (channel)\n",
    "- Gradient Boosting (HGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq-enc added: ['user_location_city_freq', 'user_location_region_freq', 'hotel_market_freq']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, gc\n",
    "\n",
    "high_card_cols = [c for c in ['user_location_city','user_location_region','hotel_market'] if c in X_train.columns]\n",
    "\n",
    "# drop old freq cols if you re-run\n",
    "for col in high_card_cols:\n",
    "    for df_ in (X_train, X_test):\n",
    "        if col + '_freq' in df_.columns:\n",
    "            df_.drop(columns=col + '_freq', inplace=True)\n",
    "\n",
    "# compute counts on TRAIN only; map to both\n",
    "for col in high_card_cols:\n",
    "    vc = X_train[col].value_counts()\n",
    "    X_train[col + '_freq'] = X_train[col].map(vc).fillna(0).astype('int32')\n",
    "    X_test[col + '_freq']  = X_test[col].map(vc).fillna(0).astype('int32')\n",
    "\n",
    "gc.collect()\n",
    "print(\"Freq-enc added:\", [c+'_freq' for c in high_card_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummies done. Shapes: (800000, 38) (200000, 38)\n"
     ]
    }
   ],
   "source": [
    "low_card = [c for c in ['channel'] if c in X_train.columns]\n",
    "if low_card:\n",
    "    X_train = pd.get_dummies(X_train, columns=low_card, dtype='int8')\n",
    "    X_test  = pd.get_dummies(X_test,  columns=low_card, dtype='int8')\n",
    "    # align test columns to train\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Dummies done. Shapes:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downcast complete.\n"
     ]
    }
   ],
   "source": [
    "# replace inf, fill NaNs; then downcast big dtypes\n",
    "for df_ in (X_train, X_test):\n",
    "    df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_.fillna(-1, inplace=True)\n",
    "\n",
    "# downcast float64 -> float32, int64 -> int32\n",
    "float_cols = X_train.select_dtypes(include=['float64']).columns\n",
    "int_cols   = X_train.select_dtypes(include=['int64']).columns\n",
    "X_train[float_cols] = X_train[float_cols].astype('float32')\n",
    "X_test[float_cols]  = X_test[float_cols].astype('float32')\n",
    "X_train[int_cols]   = X_train[int_cols].astype('int32')\n",
    "X_test[int_cols]    = X_test[int_cols].astype('int32')\n",
    "\n",
    "gc.collect()\n",
    "print(\"Downcast complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF ] Top-1: 0.20203 | Top-5: 0.51397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=150,     # lighter than 400 for RAM\n",
    "    max_depth=20,        # cap depth to control size\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)\n",
    "\n",
    "rf_top1 = accuracy_score(y_test, y_pred)\n",
    "rf_top5 = top_k_accuracy_score(y_test, y_proba, k=5)\n",
    "print(f\"[RF ] Top-1: {rf_top1:.5f} | Top-5: {rf_top5:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: ['user_location_city_freq_log', 'user_location_region_freq_log', 'hotel_market_freq_log']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# whichever you created earlier\n",
    "high_card_cols = [c for c in ['user_location_city','user_location_region','hotel_market'] if c in X_train.columns]\n",
    "\n",
    "# add log1p of *_freq\n",
    "for col in high_card_cols:\n",
    "    fcol = col + '_freq'\n",
    "    if fcol in X_train.columns:\n",
    "        X_train[fcol + '_log'] = np.log1p(X_train[fcol]).astype('float32')\n",
    "        X_test[fcol + '_log']  = np.log1p(X_test[fcol]).astype('float32')\n",
    "\n",
    "print(\"Added:\", [c+'_freq_log' for c in high_card_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score (rough): 0.22565625\n",
      "[RF ] Top-1: 0.22897 | Top-5: 0.54304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,     # up from 150\n",
    "    max_depth=24,        # still capped to control size\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    oob_score=True,      # quick overfit sanity check\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)\n",
    "\n",
    "print(\"OOB score (rough):\", getattr(rf, \"oob_score_\", None))\n",
    "print(f\"[RF ] Top-1: {accuracy_score(y_test, y_pred):.5f} | Top-5: {top_k_accuracy_score(y_test, y_proba, k=5):.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More features and trying to make classes balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: total_guests, has_children, rooms_per_guest\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, gc\n",
    "\n",
    "for df_ in (X_train, X_test):\n",
    "    # total guests\n",
    "    if 'total_guests' not in df_.columns and {'srch_adults_cnt','srch_children_cnt'}.issubset(df_.columns):\n",
    "        df_['total_guests'] = (df_['srch_adults_cnt'] + df_['srch_children_cnt']).astype('int16')\n",
    "\n",
    "    # has children flag\n",
    "    if 'has_children' not in df_.columns and 'srch_children_cnt' in df_.columns:\n",
    "        df_['has_children'] = (df_['srch_children_cnt'] > 0).astype('int8')\n",
    "\n",
    "    # rooms per guest (avoid div by zero)\n",
    "    if 'rooms_per_guest' not in df_.columns and {'srch_room_cnt','total_guests'}.issubset(df_.columns):\n",
    "        df_['rooms_per_guest'] = (df_['srch_room_cnt'] / df_['total_guests'].clip(lower=1)).astype('float32')\n",
    "\n",
    "# cleanliness\n",
    "for df_ in (X_train, X_test):\n",
    "    df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_.fillna(-1, inplace=True)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Added: total_guests, has_children, rooms_per_guest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added pair features: ['ct_user_hotel_country', 'ct_posa_hotel_cont', 'ct_market_month'] and their *_log versions\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "def add_pair_count_feature(Xtr, Xte, keys, new_name):\n",
    "    g = Xtr.groupby(keys).size().rename(new_name)\n",
    "    # join keeps row order + is memory-safe\n",
    "    Xtr = Xtr.join(g, on=keys)\n",
    "    Xte = Xte.join(g, on=keys)\n",
    "    Xtr[new_name] = Xtr[new_name].fillna(0).astype('int32')\n",
    "    Xte[new_name] = Xte[new_name].fillna(0).astype('int32')\n",
    "    # also add log version (smoother scale)\n",
    "    Xtr[new_name + '_log'] = np.log1p(Xtr[new_name]).astype('float32')\n",
    "    Xte[new_name + '_log'] = np.log1p(Xte[new_name]).astype('float32')\n",
    "    return Xtr, Xte\n",
    "\n",
    "pairs = []\n",
    "if {'user_location_country','hotel_country'}.issubset(X_train.columns):\n",
    "    pairs.append((['user_location_country','hotel_country'], 'ct_user_hotel_country'))\n",
    "if {'posa_continent','hotel_continent'}.issubset(X_train.columns):\n",
    "    pairs.append((['posa_continent','hotel_continent'], 'ct_posa_hotel_cont'))\n",
    "if {'hotel_market','checkin_month'}.issubset(X_train.columns):\n",
    "    pairs.append((['hotel_market','checkin_month'], 'ct_market_month'))\n",
    "\n",
    "for keys, name in pairs:\n",
    "    X_train, X_test = add_pair_count_feature(X_train, X_test, keys, name)\n",
    "\n",
    "gc.collect()\n",
    "print(\"Added pair features:\", [name for _, name in pairs], \"and their *_log versions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF ] Top-1: 0.22662 | Top-5: 0.53526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "import gc\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=320,        # a bit more capacity\n",
    "    max_depth=26,           # still capped to control memory\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced_subsample',  # helps with cluster imbalance\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred  = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)\n",
    "\n",
    "print(f\"[RF ] Top-1: {accuracy_score(y_test, y_pred):.5f} | Top-5: {top_k_accuracy_score(y_test, y_proba, k=5):.5f}\")\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling back the pair features additions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 0.22286625\n",
      "[RF-rollback] Top-1: 0.22589 | Top-5: 0.54056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
    "\n",
    "# drop only if present\n",
    "to_drop = [\n",
    "    'ct_user_hotel_country','ct_user_hotel_country_log',\n",
    "    'ct_posa_hotel_cont','ct_posa_hotel_cont_log',\n",
    "    'ct_market_month','ct_market_month_log'\n",
    "]\n",
    "for c in to_drop:\n",
    "    if c in X_train.columns:\n",
    "        X_train.drop(columns=c, inplace=True, errors='ignore')\n",
    "        X_test.drop(columns=c, inplace=True, errors='ignore')\n",
    "\n",
    "# same settings that gave you ~0.543 before\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=24,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred  = rf.predict(X_test)\n",
    "y_proba = rf.predict_proba(X_test)\n",
    "print(\"OOB score:\", getattr(rf, \"oob_score_\", None))\n",
    "print(f\"[RF-rollback] Top-1: {accuracy_score(y_test, y_pred):.5f} | Top-5: {top_k_accuracy_score(y_test, y_proba, k=5):.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm hitting diminishing returns for each improvement now. Will focus again on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept: 32 of 41\n"
     ]
    }
   ],
   "source": [
    "# Reducing columns by cumulative importance\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "imp = pd.Series(rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "cum = (imp.cumsum() / imp.sum())\n",
    "keep_cols = cum[cum <= 0.99].index  # keep features that explain 99% of importance\n",
    "# fallback: always keep at least 25 features\n",
    "if len(keep_cols) < 25: keep_cols = imp.index[:25]\n",
    "\n",
    "Xtr = X_train[keep_cols]\n",
    "Xte = X_test[keep_cols]\n",
    "print(\"Kept:\", len(keep_cols), \"of\", len(imp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric cols: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, gc\n",
    "\n",
    "# free old big objects if they exist\n",
    "for name in ['rf','rf_reduced','hgb','et','y_pred','y_proba']:\n",
    "    if name in globals(): del globals()[name]\n",
    "gc.collect()\n",
    "\n",
    "# safety: numeric only + compact dtypes\n",
    "for df_ in (Xtr, Xte):\n",
    "    df_.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_.fillna(-1, inplace=True)\n",
    "    for c in df_.select_dtypes('float64').columns: df_[c] = df_[c].astype('float32')\n",
    "    for c in df_.select_dtypes('int64').columns:   df_[c] = df_[c].astype('int32')\n",
    "\n",
    "# quick check: any object/datetime left?\n",
    "print(\"Non-numeric cols:\", list(Xtr.select_dtypes(include=['object','datetime64[ns]']).columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF(reduced) trained.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_reduced = RandomForestClassifier(\n",
    "    n_estimators=220,     # lighter\n",
    "    max_depth=22,        # cap tree size\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    max_samples=0.6,     # each tree uses 60% rows -> big RAM saver\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_reduced.fit(Xtr, y_train)\n",
    "print(\"RF(reduced) trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5: 0.536725\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top5_acc_batch(model, X, y, batch=40000):\n",
    "    classes = model.classes_\n",
    "    y_arr = np.asarray(y); n = len(y_arr); correct = 0\n",
    "    for i in range(0, n, batch):\n",
    "        proba = model.predict_proba(X.iloc[i:i+batch])\n",
    "        top5_idx = np.argpartition(proba, -5, axis=1)[:, -5:]\n",
    "        correct += (y_arr[i:i+batch].reshape(-1,1) == classes[top5_idx]).any(axis=1).sum()\n",
    "    return correct / n\n",
    "\n",
    "print(\"Top-5:\", top5_acc_batch(rf_reduced, Xte, y_test, batch=30000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 : 0.536725\n",
      "Top-10: 0.714225\n"
     ]
    }
   ],
   "source": [
    "# Top 5 and Top 10\n",
    "import numpy as np\n",
    "\n",
    "def topk_multi_acc_batch(model, X, y, ks=(5, 10), batch=40000):\n",
    "    classes = model.classes_\n",
    "    y_arr = np.asarray(y)\n",
    "    n = len(y_arr)\n",
    "    correct = {k: 0 for k in ks}\n",
    "\n",
    "    for i in range(0, n, batch):\n",
    "        Xb = X.iloc[i:i+batch]\n",
    "        yb = y_arr[i:i+batch].reshape(-1, 1)\n",
    "        proba = model.predict_proba(Xb)  # compute once per batch\n",
    "\n",
    "        for k in ks:\n",
    "            k_eff = min(k, proba.shape[1])              # safety if k > #classes\n",
    "            idx = np.argpartition(proba, -k_eff, axis=1)[:, -k_eff:]\n",
    "            labels = classes[idx]\n",
    "            correct[k] += (yb == labels).any(axis=1).sum()\n",
    "\n",
    "    return {k: correct[k] / n for k in ks}\n",
    "\n",
    "accs = topk_multi_acc_batch(rf_reduced, Xte, y_test, ks=(5, 10), batch=30000)\n",
    "print(f\"Top-5 : {accs[5]:.6f}\")\n",
    "print(f\"Top-10: {accs[10]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.47      0.30      1298\n",
      "           1       0.32      0.93      0.48      2541\n",
      "           2       0.21      0.23      0.22      3025\n",
      "           3       0.65      0.08      0.14       826\n",
      "           4       0.22      0.22      0.22      2390\n",
      "           5       0.17      0.14      0.16      2866\n",
      "           6       0.30      0.12      0.17      2950\n",
      "           7       0.29      0.12      0.17      2331\n",
      "           8       0.29      0.32      0.30      1470\n",
      "           9       0.20      0.21      0.21      3018\n",
      "          10       0.32      0.09      0.13      2081\n",
      "          11       0.25      0.12      0.16      1868\n",
      "          12       0.31      0.22      0.26      1081\n",
      "          13       0.26      0.11      0.16      2880\n",
      "          14       0.51      0.05      0.09      1040\n",
      "          15       0.30      0.14      0.19      2623\n",
      "          16       0.24      0.08      0.12      3776\n",
      "          17       0.28      0.08      0.12      1401\n",
      "          18       0.19      0.13      0.15      3745\n",
      "          19       0.20      0.14      0.16      2118\n",
      "          20       0.37      0.10      0.16       859\n",
      "          21       0.20      0.18      0.19      3441\n",
      "          22       0.21      0.32      0.25      1467\n",
      "          23       0.48      0.05      0.10      1087\n",
      "          24       0.62      0.10      0.17       824\n",
      "          25       0.18      0.19      0.18      3072\n",
      "          26       0.28      0.38      0.33      1102\n",
      "          27       0.83      0.69      0.76       172\n",
      "          28       0.24      0.20      0.22      4222\n",
      "          29       0.22      0.17      0.19      2328\n",
      "          30       0.27      0.10      0.15      1870\n",
      "          31       0.33      0.12      0.18       806\n",
      "          32       0.31      0.13      0.19      2805\n",
      "          33       0.25      0.09      0.14      2557\n",
      "          34       0.20      0.30      0.24      1270\n",
      "          35       0.39      0.06      0.10       480\n",
      "          36       0.24      0.30      0.27      2680\n",
      "          37       0.23      0.10      0.14      2679\n",
      "          38       0.35      0.20      0.25      1094\n",
      "          39       0.24      0.12      0.16      2468\n",
      "          40       0.47      0.07      0.12      2037\n",
      "          41       0.23      0.10      0.13      3282\n",
      "          42       0.21      0.18      0.20      4900\n",
      "          43       0.27      0.21      0.24      2160\n",
      "          44       0.37      0.09      0.14       731\n",
      "          45       0.42      0.18      0.25      1201\n",
      "          46       0.23      0.44      0.31      3072\n",
      "          47       0.41      0.07      0.12      2943\n",
      "          48       0.19      0.19      0.19      5782\n",
      "          49       0.22      0.12      0.15      1573\n",
      "          50       0.31      0.10      0.15      3643\n",
      "          51       0.45      0.06      0.11      2045\n",
      "          52       0.34      0.11      0.16       558\n",
      "          53       0.46      0.06      0.11       342\n",
      "          54       0.58      0.46      0.51      1420\n",
      "          55       0.25      0.18      0.21      2346\n",
      "          56       0.23      0.62      0.33      1915\n",
      "          57       0.41      0.10      0.16       949\n",
      "          58       0.20      0.11      0.14      2087\n",
      "          59       0.22      0.25      0.24      4414\n",
      "          60       0.43      0.07      0.12       545\n",
      "          61       0.33      0.13      0.19      1841\n",
      "          62       0.22      0.21      0.21      2718\n",
      "          63       0.29      0.45      0.35      1005\n",
      "          64       0.19      0.31      0.24      3209\n",
      "          65       0.36      0.85      0.51      1414\n",
      "          66       0.42      0.25      0.32       636\n",
      "          67       0.25      0.32      0.28      1484\n",
      "          68       0.19      0.11      0.14      2836\n",
      "          69       0.32      0.03      0.06      1238\n",
      "          70       0.20      0.20      0.20      2454\n",
      "          71       0.24      0.29      0.27       620\n",
      "          72       0.23      0.05      0.09      2883\n",
      "          73       0.30      0.13      0.18       969\n",
      "          74       0.95      0.89      0.92       159\n",
      "          75       0.32      0.13      0.19       750\n",
      "          76       0.56      0.05      0.09      1288\n",
      "          77       0.22      0.14      0.17      2641\n",
      "          78       0.27      0.12      0.17      1696\n",
      "          79       0.37      0.16      0.22      1421\n",
      "          80       0.46      0.50      0.48       517\n",
      "          81       0.28      0.26      0.27      2052\n",
      "          82       0.20      0.53      0.29      3606\n",
      "          83       0.18      0.10      0.13      2211\n",
      "          84       0.31      0.06      0.11       695\n",
      "          85       0.32      0.13      0.18      1574\n",
      "          86       0.33      0.06      0.10       498\n",
      "          87       0.49      0.09      0.15       419\n",
      "          88       0.62      0.03      0.05       475\n",
      "          89       0.52      0.05      0.10      1007\n",
      "          90       0.20      0.05      0.08      1598\n",
      "          91       0.13      0.66      0.22      8077\n",
      "          92       0.45      0.20      0.28       420\n",
      "          93       0.47      0.03      0.06       604\n",
      "          94       0.60      0.04      0.07      1835\n",
      "          95       0.15      0.41      0.22      3673\n",
      "          96       0.28      0.11      0.16      1110\n",
      "          97       0.20      0.13      0.16      1939\n",
      "          98       0.18      0.31      0.23      3265\n",
      "          99       0.23      0.18      0.20      2607\n",
      "\n",
      "    accuracy                           0.22    200000\n",
      "   macro avg       0.32      0.20      0.21    200000\n",
      "weighted avg       0.27      0.22      0.20    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_top1 = rf_reduced.predict(Xte)\n",
    "print(classification_report(y_test, y_pred_top1, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing no. of columns (32 down from 41) and training on 60% of the rows didn't impact the accuracy score negatively"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
